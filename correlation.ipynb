{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from intervaltree import IntervalTree\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from scipy.stats import pearsonr, zscore\n",
    "\n",
    "PLOT_Y_LIM = 7.5\n",
    "GENE_MERGE_DISTANCE = 2_000_000\n",
    "ARM_COLORS = {'p': 'tab:blue', 'q': 'tab:orange', 'spanning': 'tab:green', None: 'grey'}\n",
    "\n",
    "BASE_DATA_DIR = Path('data')\n",
    "PLOT_OUTPUT_DIR = Path('graphics')\n",
    "PLOT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CASES_FILE_PATH = BASE_DATA_DIR / 'cases.csv'\n",
    "CYTOBAND_FILE_PATH = BASE_DATA_DIR / 'cytoBand.txt'\n",
    "RELEVANT_GENES_FILE_PATH = BASE_DATA_DIR / 'relevant_genes.csv'\n",
    "\n",
    "# For cases_df processing\n",
    "CASES_COLUMNS_INDICES = [0, 1, 2, 3, 4, 5, 6, 13, 14]\n",
    "CASES_COLUMN_NAMES = ['patient_id', 'case_n_number', 'age', 'sex', 'tumor_type', 'diagnosis', 'DIN', 'sentrix_id', 'barcode']\n",
    "\n",
    "# For cytoband_df processing\n",
    "CYTOBAND_COLUMN_NAMES = ['chromosome', 'start', 'end', 'band', 'giemsa']\n",
    "\n",
    "# For relevant_genes_df processing\n",
    "RELEVANT_GENES_COLUMN_NAMES = ['gene', 'chromosome', 'start', 'end']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f9b6aff101458ae",
   "metadata": {},
   "source": [
    "def _sanitize_chromosome_column(df, chromosome_col='chromosome'):\n",
    "    \"\"\"\n",
    "    Converts a chromosome column to numeric Int64Dtype, removing 'chr' prefix.\n",
    "    Rows with unparsable chromosome values (e.g., 'X', 'Y') are dropped.\n",
    "    \"\"\"\n",
    "    if chromosome_col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    df[chromosome_col] = (\n",
    "        df[chromosome_col]\n",
    "        .astype(str)\n",
    "        .str.replace('chr', '', regex=False)\n",
    "        .pipe(pd.to_numeric, errors='coerce')\n",
    "    )\n",
    "    df = df.dropna(subset=[chromosome_col])\n",
    "    df[chromosome_col] = df[chromosome_col].astype(pd.Int64Dtype())\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f1dee0dd1ec9b04",
   "metadata": {},
   "source": [
    "def load_and_preprocess_cases(file_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the cases data from a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1', decimal=',')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Cases file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.iloc[:, CASES_COLUMNS_INDICES]\n",
    "    df.columns = CASES_COLUMN_NAMES\n",
    "\n",
    "    # Remove leading 'P' from patient_id and convert to integer\n",
    "    df['patient_id'] = df['patient_id'].astype(str).str.lstrip('P').astype(int)\n",
    "\n",
    "    if 'DIN' in df.columns:\n",
    "        df['DIN'] = pd.to_numeric(df['DIN'], errors='coerce')\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8144f3bc33a9489",
   "metadata": {},
   "source": [
    "def load_and_preprocess_cytoband(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', names=CYTOBAND_COLUMN_NAMES)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Cytoband file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    return _sanitize_chromosome_column(df, 'chromosome')\n",
    "\n",
    "\n",
    "def calculate_chromosome_features(cytoband_df):\n",
    "    if cytoband_df.empty:\n",
    "        return pd.DataFrame(columns=['chromosome', 'length', 'chromosome_absolute_start']), {}\n",
    "    chromosomes_df = (\n",
    "        cytoband_df\n",
    "        .groupby('chromosome')\n",
    "        .agg(length=('end', 'max'))\n",
    "        .reset_index()\n",
    "        .sort_values('chromosome')\n",
    "    )\n",
    "    chromosomes_df['chromosome_absolute_start'] = chromosomes_df['length'].cumsum() - chromosomes_df['length']\n",
    "    chromosome_start_map = chromosomes_df.set_index('chromosome')['chromosome_absolute_start'].to_dict()\n",
    "    return chromosomes_df, chromosome_start_map\n",
    "\n",
    "\n",
    "def create_arm_mapping_df(cytoband_df, chromosome_start_map):\n",
    "    if cytoband_df.empty or not chromosome_start_map:\n",
    "        return pd.DataFrame(columns=['chromosome', 'arm', 'arm_start', 'arm_end', 'arm_abs_start', 'arm_abs_end'])\n",
    "    chromosome_starts_series = pd.Series(chromosome_start_map, name='chr_abs_start').reset_index().rename(\n",
    "        columns={'index': 'chromosome_num'})\n",
    "    arm_df = (\n",
    "        cytoband_df\n",
    "        .assign(arm=lambda x: x['band'].astype(str).str[0].str.lower())\n",
    "        .groupby(['chromosome', 'arm'])\n",
    "        .agg(arm_start=('start', 'min'), arm_end=('end', 'max'))\n",
    "        .reset_index()\n",
    "        .merge(chromosome_starts_series, left_on='chromosome', right_on='chromosome_num')\n",
    "        .assign(\n",
    "            arm_abs_start=lambda x: x['chr_abs_start'] + x['arm_start'],\n",
    "            arm_abs_end=lambda x: x['chr_abs_start'] + x['arm_end']\n",
    "        )\n",
    "        [['chromosome', 'arm', 'arm_start', 'arm_end', 'arm_abs_start', 'arm_abs_end']]\n",
    "    )\n",
    "    return arm_df\n",
    "\n",
    "\n",
    "def create_arm_lookup_table(arm_mapping_df):\n",
    "    \"\"\"Pivots arm_mapping_df for easy lookup of p/q arm start/end.\"\"\"\n",
    "    if arm_mapping_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    arm_lookup = arm_mapping_df.pivot(index='chromosome', columns='arm',\n",
    "                                      values=['arm_start', 'arm_end'])\n",
    "    if not arm_lookup.empty:\n",
    "        new_cols = []\n",
    "        for val_type in ['arm_start', 'arm_end']:\n",
    "            for arm_type in ['p', 'q']:\n",
    "                if (val_type, arm_type) in arm_lookup.columns:\n",
    "                    new_cols.append(f'{arm_type}_{val_type.split(\"_\")[1]}')  # e.g. p_start, q_end\n",
    "                else:\n",
    "                    new_cols.append(None)  # Placeholder for missing data\n",
    "\n",
    "        cols_to_rename = {}\n",
    "        if ('arm_start', 'p') in arm_lookup.columns: cols_to_rename[('arm_start', 'p')] = 'p_start'\n",
    "        if ('arm_end', 'p') in arm_lookup.columns: cols_to_rename[('arm_end', 'p')] = 'p_end'\n",
    "        if ('arm_start', 'q') in arm_lookup.columns: cols_to_rename[('arm_start', 'q')] = 'q_start'\n",
    "        if ('arm_end', 'q') in arm_lookup.columns: cols_to_rename[('arm_end', 'q')] = 'q_end'\n",
    "\n",
    "        arm_lookup.columns = ['_'.join(col).strip() for col in arm_lookup.columns.values]  # Flatten MultiIndex\n",
    "        arm_lookup = arm_lookup.rename(columns={\n",
    "            'arm_start_p': 'p_start', 'arm_end_p': 'p_end',\n",
    "            'arm_start_q': 'q_start', 'arm_end_q': 'q_end'\n",
    "        })\n",
    "        for col in ['p_start', 'p_end', 'q_start', 'q_end']:\n",
    "            if col not in arm_lookup.columns:\n",
    "                arm_lookup[col] = np.nan\n",
    "    return arm_lookup"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c57f1453bc63e98",
   "metadata": {},
   "source": [
    "def load_and_preprocess_relevant_genes(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=';', names=RELEVANT_GENES_COLUMN_NAMES)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Relevant genes file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    # _sanitize_chromosome_column ensures 'chromosome' is int\n",
    "    return _sanitize_chromosome_column(df, 'chromosome')\n",
    "\n",
    "\n",
    "def build_gene_interval_trees(relevant_genes_df):\n",
    "    \"\"\"Builds a dictionary of IntervalTrees for gene lookups, per chromosome.\"\"\"\n",
    "    if relevant_genes_df.empty: return {}\n",
    "    trees = {}\n",
    "    for _, row in relevant_genes_df.iterrows():\n",
    "        chrom = row.chromosome\n",
    "        if chrom not in trees:\n",
    "            trees[chrom] = IntervalTree()\n",
    "\n",
    "        start = int(row.start)\n",
    "        end = int(row.end) + 1\n",
    "\n",
    "        # Store the original start/end in the data payload for reference.\n",
    "        trees[chrom].addi(start, end, {'gene': row.gene, 'start': int(row.start), 'end': int(row.end)})\n",
    "\n",
    "    return trees\n",
    "\n",
    "\n",
    "def annotate_segments_with_genes(df, gene_interval_trees, genes_df):\n",
    "    \"\"\"\n",
    "    Annotates DataFrame segments with overlapping genes from the relevant_genes list,\n",
    "    applying logic on a per-case basis to correctly handle pre-annotated genes.\n",
    "    \"\"\"\n",
    "    if df.empty or not gene_interval_trees:\n",
    "        if 'gene' not in df.columns:\n",
    "            df['gene'] = pd.NA\n",
    "        return df\n",
    "\n",
    "    all_relevant_genes = set(genes_df['gene'])\n",
    "    case_id_col = 'case_n_number'\n",
    "\n",
    "    # Ensure a 'gene' column exists and sanitize it globally first.\n",
    "    # This is efficient and removes junk like 'Antitarget' from all rows.\n",
    "    if 'gene' not in df.columns:\n",
    "        df['gene'] = pd.NA\n",
    "    df['gene'] = df['gene'].where(df['gene'].isin(all_relevant_genes), pd.NA)\n",
    "\n",
    "    # Ensure chromosome column is numeric for tree lookups.\n",
    "    df['chromosome'] = pd.to_numeric(df['chromosome'], errors='coerce')\n",
    "\n",
    "    processed_cases = []\n",
    "    for case_id, case_df in df.groupby(case_id_col):\n",
    "        case_df = case_df.copy()\n",
    "\n",
    "        # Identify genes already validly annotated for this case\n",
    "        genes_on_panel_for_this_case = set(case_df['gene'].dropna())\n",
    "\n",
    "        # Identify rows that still need annotation within THIS case.\n",
    "        rows_to_annotate_mask = case_df['gene'].isna()\n",
    "        rows_to_annotate_indices = case_df.index[rows_to_annotate_mask]\n",
    "\n",
    "        # Iterate through and annotate only the necessary rows for this case.\n",
    "        for index in rows_to_annotate_indices:\n",
    "            row = case_df.loc[index]\n",
    "\n",
    "            if pd.isna(row.chromosome):\n",
    "                continue\n",
    "\n",
    "            tree = gene_interval_trees.get(int(row.chromosome))\n",
    "            if not tree:\n",
    "                continue\n",
    "\n",
    "            overlaps = tree.overlap(row.start, row.end)\n",
    "            if overlaps:\n",
    "                # Filter out genes that are already on this specific case's panel.\n",
    "                additional_gene_overlaps = {\n",
    "                    iv for iv in overlaps if iv.data['gene'] not in genes_on_panel_for_this_case\n",
    "                }\n",
    "\n",
    "                if additional_gene_overlaps:\n",
    "                    first_overlap = sorted(additional_gene_overlaps, key=lambda i: (i.begin, i.data['gene']))[0]\n",
    "                    case_df.at[index, 'gene'] = first_overlap.data['gene']\n",
    "\n",
    "        processed_cases.append(case_df)\n",
    "\n",
    "    # Recombine all the processed cases into a single DataFrame.\n",
    "    if not processed_cases:\n",
    "        return pd.DataFrame(columns=df.columns)  # Return empty DF if no cases were processed\n",
    "\n",
    "    return pd.concat(processed_cases, ignore_index=True)\n",
    "\n",
    "\n",
    "def aggregate_data_by_gene(annotated_df, merge_distance=GENE_MERGE_DISTANCE):\n",
    "    \"\"\"Aggregates log2 data to gene level and merges nearby genes, on a per-case basis.\"\"\"\n",
    "    if (annotated_df.empty or\n",
    "            'gene' not in annotated_df.columns or\n",
    "            'absolute_start' not in annotated_df.columns or\n",
    "            'log2' not in annotated_df.columns):\n",
    "        print(\"Warning: Cannot aggregate by gene due to missing columns.\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    case_id_col = 'case_n_number'\n",
    "    if case_id_col not in annotated_df.columns:\n",
    "        print(f\"Warning: Expected column '{case_id_col}' not found.\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ngs_with_gene = annotated_df[annotated_df['gene'].notna() & annotated_df['log2'].notna()].copy()\n",
    "    if ngs_with_gene.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_cases_final_reps = []\n",
    "\n",
    "    for case_id, case_df in ngs_with_gene.groupby(case_id_col):\n",
    "\n",
    "        # Aggregate to gene-level for this single case\n",
    "        gene_reps_case = case_df.groupby('gene').agg(\n",
    "            absolute_position=('absolute_start', 'median'),\n",
    "            log2=('log2', 'median')\n",
    "        ).reset_index()\n",
    "\n",
    "        if gene_reps_case.empty:\n",
    "            continue\n",
    "\n",
    "        # Sort genes by position for this single case\n",
    "        gene_reps_case = gene_reps_case.sort_values('absolute_position').reset_index(drop=True)\n",
    "\n",
    "        # Apply only to this case's genes\n",
    "        if merge_distance <= 0:\n",
    "            final_reps_data_case = gene_reps_case.to_dict('records')\n",
    "        else:\n",
    "            groups = []\n",
    "            current_group = []\n",
    "            for _, row in gene_reps_case.iterrows():\n",
    "                if not current_group:\n",
    "                    current_group.append(row)\n",
    "                    continue\n",
    "\n",
    "                last_row_in_group = current_group[-1]\n",
    "                if (row.absolute_position - last_row_in_group.absolute_position) > merge_distance:\n",
    "                    groups.append(current_group)\n",
    "                    current_group = [row]\n",
    "                else:\n",
    "                    current_group.append(row)\n",
    "\n",
    "            if current_group:\n",
    "                groups.append(current_group)\n",
    "\n",
    "            # Re-aggregate the grouped genes for this single case\n",
    "            final_reps_data_case = []\n",
    "            for group in groups:\n",
    "                group_df = pd.DataFrame(group)\n",
    "                if len(group_df) == 1:\n",
    "                    merged_row = group_df.iloc[0].to_dict()\n",
    "                else:\n",
    "                    unique_genes = sorted(list(set(group_df['gene'])))\n",
    "                    merged_name = _merge_gene_names(unique_genes)\n",
    "                    merged_row = {\n",
    "                        'gene': merged_name,\n",
    "                        'absolute_position': group_df['absolute_position'].median(),\n",
    "                        'log2': group_df.loc[group_df['log2'].abs().idxmax()]['log2']\n",
    "                    }\n",
    "                merged_row[case_id_col] = case_id  # Add the case identifier back\n",
    "                final_reps_data_case.append(merged_row)\n",
    "\n",
    "        all_cases_final_reps.extend(final_reps_data_case)\n",
    "\n",
    "    if not all_cases_final_reps:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Create the final DataFrame from all processed cases\n",
    "    merged_gene_reps = pd.DataFrame(all_cases_final_reps)\n",
    "    merged_gene_reps['log2'] = merged_gene_reps['log2'].clip(lower=-PLOT_Y_LIM, upper=PLOT_Y_LIM)\n",
    "\n",
    "    return merged_gene_reps\n",
    "\n",
    "\n",
    "def _merge_gene_names(gene_list):\n",
    "    \"\"\"\n",
    "    Merges a list of gene names intelligently.\n",
    "    e.g., ['CDKN2A', 'CDKN2B'] becomes 'CDKN2A/B'.\n",
    "    \"\"\"\n",
    "    if len(gene_list) <= 1:\n",
    "        return '/'.join(gene_list)\n",
    "\n",
    "    prefix = path.commonprefix(gene_list)\n",
    "\n",
    "    # If the prefix is trivial, don't shorten, just join\n",
    "    if len(prefix) < 3:\n",
    "        return '/'.join(gene_list)\n",
    "\n",
    "    # Keep the first gene name whole, append only suffixes of the rest\n",
    "    suffixes = [gene[len(prefix):] for gene in gene_list[1:]]\n",
    "    return '/'.join([gene_list[0]] + suffixes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d5dc7ce39bac0ff",
   "metadata": {},
   "source": [
    "def load_ngs_cnr_file(item_id, case_id, base_dir):\n",
    "    \"\"\"Load NGS raw data from .cnr files\"\"\"\n",
    "    cnr_dir = base_dir / 'ngs/cnr'\n",
    "    item_id_str = str(item_id) if pd.notna(item_id) else \"\"\n",
    "    if not item_id_str:\n",
    "        return None\n",
    "\n",
    "    matches = list(cnr_dir.glob(f'*{item_id_str}*.cnr'))\n",
    "    if not matches:\n",
    "        print(f\"CNR file not found for {item_id}\")\n",
    "        return None\n",
    "\n",
    "    path = matches[0]\n",
    "    try:\n",
    "        print(f\"Loading CNR file: {path}\")\n",
    "        df = pd.read_csv(path, sep='\\t', header=0)\n",
    "        print(f\"CNR file shape: {df.shape}\")\n",
    "\n",
    "        # Clean up the data\n",
    "        df['case_n_number'] = case_id\n",
    "        df['barcode'] = item_id\n",
    "\n",
    "        # Remove Antitarget entries and extreme values\n",
    "        is_antitarget = (df['gene'] == 'Antitarget')\n",
    "        df.loc[is_antitarget, 'gene'] = pd.NA\n",
    "        if 'log2' in df.columns:\n",
    "            df = df[df['log2'].abs() < 6].copy()\n",
    "\n",
    "        return _sanitize_chromosome_column(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CNR file {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_ngs_cns_file(item_id, case_id, base_dir):\n",
    "    \"\"\"Load NGS segments from .cns files\"\"\"\n",
    "    cns_dir = base_dir / 'ngs/cns'\n",
    "    item_id_str = str(item_id) if pd.notna(item_id) else \"\"\n",
    "    if not item_id_str:\n",
    "        return None\n",
    "\n",
    "    matches = list(cns_dir.glob(f'*{item_id_str}*.cns'))\n",
    "    if not matches:\n",
    "        print(f\"CNS file not found for {item_id}\")\n",
    "        return None\n",
    "\n",
    "    path = matches[0]\n",
    "    try:\n",
    "        print(f\"Loading CNS file: {path}\")\n",
    "        df = pd.read_csv(path, sep='\\t', header=0)\n",
    "        print(f\"CNS file shape: {df.shape}\")\n",
    "\n",
    "        # Clean up the data\n",
    "        df['case_n_number'] = case_id\n",
    "        df['barcode'] = item_id\n",
    "\n",
    "        # Filter extreme values\n",
    "        if 'log2' in df.columns:\n",
    "            df = df[df['log2'].abs() < 6].copy()\n",
    "\n",
    "        return _sanitize_chromosome_column(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CNS file {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_epic_igv_file(item_id, case_id, base_dir):\n",
    "    \"\"\"Load EPIC raw data from .igv files\"\"\"\n",
    "    igv_dir = base_dir / 'epic/igv'\n",
    "    path = igv_dir / f'{item_id}_CNV.igv'\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"IGV file not found: {path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading IGV file: {path}\")\n",
    "        df = pd.read_csv(path, sep='\\t', header=0)\n",
    "        print(f\"IGV file columns: {df.columns.tolist()}\")\n",
    "        print(f\"IGV file shape: {df.shape}\")\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"IGV file is empty: {path}\")\n",
    "            return None\n",
    "\n",
    "        # Get the column name for the log2 values (should be the last column, typically sample ID)\n",
    "        log2_col = df.columns[-1]\n",
    "        print(f\"Using column '{log2_col}' as log2 values\")\n",
    "\n",
    "        # Rename columns to match expected format\n",
    "        df = df.rename(columns={\n",
    "            'Chromosome': 'chromosome',\n",
    "            'Start': 'start',\n",
    "            'End': 'end',\n",
    "            log2_col: 'log2'\n",
    "        })\n",
    "\n",
    "        # Keep only the columns we need\n",
    "        df = df[['chromosome', 'start', 'end', 'log2']]\n",
    "        df['case_n_number'] = case_id\n",
    "        df['sentrix_id'] = item_id\n",
    "\n",
    "        return _sanitize_chromosome_column(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading IGV file {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_epic_seg_file(item_id, case_id, base_dir):\n",
    "    \"\"\"Load EPIC segments from .seg files\"\"\"\n",
    "    seg_dir = base_dir / 'epic/seg'\n",
    "\n",
    "    # Try to find the seg file - they might have different naming patterns\n",
    "    matches = list(seg_dir.glob(f'*{item_id}*.seg'))\n",
    "    if not matches:\n",
    "        print(f\"SEG file not found for {item_id}\")\n",
    "        return None\n",
    "\n",
    "    path = matches[0]\n",
    "    try:\n",
    "        print(f\"Loading SEG file: {path}\")\n",
    "        df = pd.read_csv(path, sep='\\t', header=0)\n",
    "        print(f\"SEG file columns: {df.columns.tolist()}\")\n",
    "        print(f\"SEG file shape: {df.shape}\")\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"SEG file is empty: {path}\")\n",
    "            return None\n",
    "\n",
    "        # The SEG files have a specific format - extract the relevant columns\n",
    "        # Find columns that contain the sample information\n",
    "        sample_cols = [col for col in df.columns if item_id in col]\n",
    "\n",
    "        if not sample_cols:\n",
    "            print(f\"No sample columns found for {item_id} in SEG file\")\n",
    "            return None\n",
    "\n",
    "        # Extract chromosome, start, end, and log2 values\n",
    "        # Assuming the format: ID, chrom, loc.start, loc.end, num.mark, bstat, pval, seg.mean, seg.median\n",
    "        chrom_col = [col for col in df.columns if 'chrom' in col][0]\n",
    "        start_col = [col for col in df.columns if 'loc.start' in col][0]\n",
    "        end_col = [col for col in df.columns if 'loc.end' in col][0]\n",
    "\n",
    "        # Use seg.mean as the log2 value (this is the segment mean)\n",
    "        log2_col = [col for col in df.columns if 'seg.mean' in col][0]\n",
    "\n",
    "        # Create cleaned dataframe\n",
    "        cleaned_df = pd.DataFrame({\n",
    "            'chromosome': df[chrom_col],\n",
    "            'start': df[start_col],\n",
    "            'end': df[end_col],\n",
    "            'log2': df[log2_col]\n",
    "        })\n",
    "\n",
    "        cleaned_df['case_n_number'] = case_id\n",
    "        cleaned_df['sentrix_id'] = item_id\n",
    "\n",
    "        return _sanitize_chromosome_column(cleaned_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SEG file {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _normalize_log2(dfs, col='log2'):\n",
    "    \"\"\"\n",
    "    Normalize log2 values across datasets using z-score normalization.\n",
    "    This ensures all datasets (raw and segments, NGS and EPIC) are on the same scale.\n",
    "    \"\"\"\n",
    "    if not dfs:\n",
    "        print(\"Warning: No dataframes provided for normalization\")\n",
    "        return []\n",
    "\n",
    "    # Collect all log2 values from all dataframes\n",
    "    all_log2_values = []\n",
    "    valid_dfs = []\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        if df is None or df.empty:\n",
    "            print(f\"Warning: Dataframe {i} is None or empty, skipping\")\n",
    "            continue\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in dataframe {i}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Get valid (non-NaN) log2 values\n",
    "        valid_log2 = df[col].dropna()\n",
    "        if valid_log2.empty:\n",
    "            print(f\"Warning: No valid log2 values in dataframe {i}\")\n",
    "            continue\n",
    "\n",
    "        all_log2_values.append(valid_log2)\n",
    "        valid_dfs.append(df)\n",
    "\n",
    "    if not all_log2_values:\n",
    "        print(\"Warning: No valid log2 values found across all dataframes\")\n",
    "        return [d.copy() if d is not None else pd.DataFrame() for d in dfs]\n",
    "\n",
    "    # Combine all log2 values to calculate global statistics\n",
    "    combined_log2 = pd.concat(all_log2_values, ignore_index=True)\n",
    "\n",
    "    # Calculate global mean and standard deviation\n",
    "    global_mean = combined_log2.mean()\n",
    "    global_std = combined_log2.std()\n",
    "\n",
    "    print(f\"Log2 normalization statistics:\")\n",
    "    print(f\"  - Total values: {len(combined_log2)}\")\n",
    "    print(f\"  - Global mean: {global_mean:.4f}\")\n",
    "    print(f\"  - Global std: {global_std:.4f}\")\n",
    "    print(f\"  - Value range: [{combined_log2.min():.4f}, {combined_log2.max():.4f}]\")\n",
    "\n",
    "    # Handle edge case where std is 0 or NaN\n",
    "    if pd.isna(global_std) or global_std == 0:\n",
    "        print(\"Warning: Standard deviation is 0 or NaN, using raw values without normalization\")\n",
    "        return [d.copy() if d is not None else pd.DataFrame() for d in dfs]\n",
    "\n",
    "    # Normalize each dataframe using the global statistics\n",
    "    normalized_dfs = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        if df is None or df.empty or col not in df.columns:\n",
    "            normalized_dfs.append(df.copy() if df is not None else pd.DataFrame())\n",
    "            continue\n",
    "\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply z-score normalization: (x - mean) / std\n",
    "        original_values = df_copy[col]\n",
    "        normalized_values = (original_values - global_mean) / global_std\n",
    "\n",
    "        # Count how many values were normalized\n",
    "        valid_count = original_values.notna().sum()\n",
    "\n",
    "        df_copy[col] = normalized_values\n",
    "        normalized_dfs.append(df_copy)\n",
    "\n",
    "        print(f\"  - Dataframe {i}: {valid_count} values normalized\")\n",
    "        if valid_count > 0:\n",
    "            print(f\"    Original range: [{original_values.min():.4f}, {original_values.max():.4f}]\")\n",
    "            print(f\"    Normalized range: [{normalized_values.min():.4f}, {normalized_values.max():.4f}]\")\n",
    "\n",
    "    return normalized_dfs\n",
    "\n",
    "\n",
    "def load_combine_genomic_data(cases, base_dir, data_type, file_type, id_col, case_id_col='case_n_number',\n",
    "                              l2_col='log2'):\n",
    "    \"\"\"\n",
    "    Generic function to load and combine genomic data with consistent log2 normalization\n",
    "    \n",
    "    Args:\n",
    "        cases: DataFrame with case information\n",
    "        base_dir: Base data directory\n",
    "        data_type: 'ngs' or 'epic'\n",
    "        file_type: 'raw' (cnr/igv) or 'segments' (cns/seg)\n",
    "        id_col: Column name for the ID (barcode/sentrix_id)\n",
    "        case_id_col: Column name for case ID\n",
    "        l2_col: Column name for log2 values\n",
    "    \"\"\"\n",
    "    raw_data = []\n",
    "\n",
    "    # Select appropriate loader function\n",
    "    if data_type == 'ngs' and file_type == 'raw':\n",
    "        loader_func = load_ngs_cnr_file\n",
    "        print(f\"Loading NGS raw data (.cnr files) for {len(cases)} cases...\")\n",
    "    elif data_type == 'ngs' and file_type == 'segments':\n",
    "        loader_func = load_ngs_cns_file\n",
    "        print(f\"Loading NGS segments (.cns files) for {len(cases)} cases...\")\n",
    "    elif data_type == 'epic' and file_type == 'raw':\n",
    "        loader_func = load_epic_igv_file\n",
    "        print(f\"Loading EPIC raw data (.igv files) for {len(cases)} cases...\")\n",
    "    elif data_type == 'epic' and file_type == 'segments':\n",
    "        loader_func = load_epic_seg_file\n",
    "        print(f\"Loading EPIC segments (.seg files) for {len(cases)} cases...\")\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid combination: data_type='{data_type}', file_type='{file_type}'\")\n",
    "\n",
    "    # Load data for each case\n",
    "    for _, row in cases.iterrows():\n",
    "        item_id, case_id = row[id_col], row[case_id_col]\n",
    "        if pd.isna(item_id) or pd.isna(case_id) or str(item_id) == '0':\n",
    "            print(f\"Skipping case {case_id}: missing or invalid {id_col}\")\n",
    "            continue\n",
    "\n",
    "        df = loader_func(str(item_id), str(case_id), base_dir)\n",
    "        if df is not None and not df.empty:\n",
    "            raw_data.append(df)\n",
    "            print(f\"Loaded data for case {case_id}: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"No data loaded for case {case_id}\")\n",
    "\n",
    "    if not raw_data:\n",
    "        print(\"No files were successfully loaded\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Successfully loaded {len(raw_data)} files\")\n",
    "\n",
    "    # Apply log2 normalization across all loaded files\n",
    "    print(f\"Applying log2 normalization to {data_type} {file_type} data...\")\n",
    "    normalized_data = _normalize_log2(raw_data, l2_col)\n",
    "\n",
    "    # Combine all normalized dataframes\n",
    "    if normalized_data:\n",
    "        combined_df = pd.concat(normalized_data, ignore_index=True)\n",
    "        print(f\"Combined {data_type} {file_type} data shape: {combined_df.shape}\")\n",
    "\n",
    "        # Final statistics check\n",
    "        if l2_col in combined_df.columns:\n",
    "            final_log2 = combined_df[l2_col].dropna()\n",
    "            if not final_log2.empty:\n",
    "                print(f\"Final normalized {l2_col} statistics:\")\n",
    "                print(f\"  - Mean: {final_log2.mean():.4f}\")\n",
    "                print(f\"  - Std: {final_log2.std():.4f}\")\n",
    "                print(f\"  - Range: [{final_log2.min():.4f}, {final_log2.max():.4f}]\")\n",
    "\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def add_segment_arm_classification(df, arm_lookup_table):\n",
    "    if df.empty or arm_lookup_table.empty:\n",
    "        df['segment_arm'] = None\n",
    "        return df\n",
    "    df['chromosome'] = df['chromosome'].astype(int)\n",
    "    dfa = df.merge(arm_lookup_table, on='chromosome', how='left')\n",
    "    for pos in ['start', 'end']:\n",
    "        ps, pe, qs, qe = (dfa[c].fillna(float('-inf') if 'start' in c else float('inf')) for c in\n",
    "                          ['p_start', 'p_end', 'q_start', 'q_end'])\n",
    "        dfa[f'{pos}_arm'] = np.select([(dfa[pos] >= ps) & (dfa[pos] < pe), (dfa[pos] >= qs) & (dfa[pos] < qe)],\n",
    "                                      ['p', 'q'], default=None)\n",
    "    dfa['segment_arm'] = np.where(dfa['start_arm'] == dfa['end_arm'], dfa['start_arm'], 'spanning')\n",
    "    dfa.loc[(dfa['start_arm'].notna() & dfa['end_arm'].notna() & (\n",
    "            dfa['start_arm'] != dfa['end_arm'])), 'segment_arm'] = 'spanning'\n",
    "    dfa.loc[\n",
    "        (dfa['start_arm'].isna() | dfa['end_arm'].isna()) & (dfa['start_arm'] != dfa['end_arm']), 'segment_arm'] = None\n",
    "    return dfa.drop(\n",
    "        columns=[c for c in ['p_start', 'p_end', 'q_start', 'q_end', 'start_arm', 'end_arm'] if c in dfa.columns])\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "782848c86b430081",
   "metadata": {},
   "source": [
    "def calculate_arm_log2_from_segments(classified_seg_df, arm_map_df, id_col_name='sentrix_id'):\n",
    "    \"\"\"\n",
    "    Aggregates log2 from segment data (IGV or SEG) to arm level using segment clipping.\n",
    "    Weights log2 by clipped segment coverage within the arm.\n",
    "    \"\"\"\n",
    "    if classified_seg_df.empty or arm_map_df.empty: return pd.DataFrame()\n",
    "    if 'segment_arm' not in classified_seg_df.columns: return pd.DataFrame()  # Need classification\n",
    "\n",
    "    df = classified_seg_df.copy()\n",
    "    df['chromosome'] = df['chromosome'].astype(int)\n",
    "    arm_map_df['chromosome'] = arm_map_df['chromosome'].astype(int)\n",
    "\n",
    "    results = []\n",
    "    for (case, chrom), group in df.groupby(['case_n_number', 'chromosome']):\n",
    "        chrom_arm_info = arm_map_df[arm_map_df['chromosome'] == chrom]\n",
    "        for _, arm_row in chrom_arm_info.iterrows():\n",
    "            arm, arm_start, arm_end, arm_abs_start = arm_row['arm'], arm_row['arm_start'], arm_row['arm_end'], arm_row[\n",
    "                'arm_abs_start']\n",
    "\n",
    "            # Select relevant segments (classified to this arm OR spanning) & overlapping the arm physically\n",
    "            mask = (((group['segment_arm'] == arm) | (group['segment_arm'] == 'spanning')) &\n",
    "                    (group['end'] > arm_start) & (group['start'] < arm_end))\n",
    "            relevant_segments = group[mask].copy()\n",
    "\n",
    "            item_id_val = None\n",
    "            if not relevant_segments.empty:\n",
    "                # Clip segments to arm boundaries\n",
    "                relevant_segments['s_clip'] = relevant_segments['start'].clip(lower=arm_start)\n",
    "                relevant_segments['e_clip'] = relevant_segments['end'].clip(upper=arm_end)\n",
    "                relevant_segments['clip_cov'] = relevant_segments['e_clip'] - relevant_segments['s_clip']\n",
    "                valid_clipped = relevant_segments[relevant_segments['clip_cov'] > 0]\n",
    "\n",
    "                if not valid_clipped.empty:\n",
    "                    total_clip_cov = valid_clipped['clip_cov'].sum()\n",
    "                    log2_agg = (valid_clipped['log2'] * valid_clipped[\n",
    "                        'clip_cov']).sum() / total_clip_cov if total_clip_cov > 0 else np.nan\n",
    "                    agg_start, agg_end = valid_clipped['s_clip'].min(), valid_clipped['e_clip'].max()\n",
    "                    if id_col_name in valid_clipped.columns: item_id_val = valid_clipped[id_col_name].iloc[0]\n",
    "                else:\n",
    "                    log2_agg, agg_start, agg_end = np.nan, arm_start, arm_end\n",
    "            else:\n",
    "                log2_agg, agg_start, agg_end = np.nan, arm_start, arm_end\n",
    "\n",
    "            abs_start = arm_abs_start + (agg_start - arm_start)\n",
    "            abs_end = arm_abs_start + (agg_end - arm_start)\n",
    "            entry = {'case_n_number': case, 'chromosome': chrom, 'segment_arm': arm, 'log2': log2_agg,\n",
    "                     'start': agg_start, 'end': agg_end, 'absolute_start': abs_start, 'absolute_end': abs_end}\n",
    "            if item_id_val is not None: entry[id_col_name] = item_id_val\n",
    "            results.append(entry)\n",
    "\n",
    "    return pd.DataFrame(results).dropna(subset=['log2'])\n",
    "\n",
    "\n",
    "# --- Functions specific to NGS/CNR aggregation ---\n",
    "\n",
    "def prep_ngs_agg(df, chrom_start_map):\n",
    "    \"\"\"Prepares NGS data for arm aggregation: calculates absolute midpoints and length.\"\"\"\n",
    "    if df.empty or not chrom_start_map: return df\n",
    "    df['chromosome'] = df['chromosome'].astype(int)  # Ensure int for mapping\n",
    "    # Calculate absolute start based on bin midpoint\n",
    "    df['absolute_start'] = df['chromosome'].map(chrom_start_map) + ((df['start'] + df['end']) // 2)\n",
    "    df['length'] = df['end'] - df['start']  # Length of the bin\n",
    "    return df\n",
    "\n",
    "\n",
    "def agg_ngs_points_to_arms(classified_ngs_df, chrom_features_df):\n",
    "    \"\"\"Aggregates NGS points/bins to arms based on classification ('p','q','spanning').\"\"\"\n",
    "    if classified_ngs_df.empty or 'segment_arm' not in classified_ngs_df.columns or chrom_features_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Work with valid points having classification and positive length (for weighting)\n",
    "    ngs_valid = classified_ngs_df[classified_ngs_df['segment_arm'].notna()].copy()\n",
    "    if 'length' not in ngs_valid.columns:  # Ensure length exists\n",
    "        ngs_valid['length'] = ngs_valid['end'] - ngs_valid['start']\n",
    "    ngs_valid = ngs_valid[ngs_valid['length'] > 0]\n",
    "    if ngs_valid.empty: return pd.DataFrame()\n",
    "\n",
    "    ngs_valid['chromosome'] = ngs_valid['chromosome'].astype(int)\n",
    "    chrom_features_df['chromosome'] = chrom_features_df['chromosome'].astype(int)\n",
    "\n",
    "    # Aggregate using weighted average, weighted by bin length\n",
    "    arm_agg = (\n",
    "        ngs_valid.groupby(['case_n_number', 'chromosome', 'segment_arm'])\n",
    "        .agg(\n",
    "            log2=('log2', lambda x: np.average(x, weights=ngs_valid.loc[\n",
    "                x.index, 'length']) if not x.empty and x.notna().any() else np.nan),\n",
    "            arm_start=('start', 'min'),\n",
    "            arm_end=('end', 'max'),\n",
    "            # Optional: count number of bins per arm aggregate\n",
    "            # num_bins = ('start', 'size')\n",
    "        ).reset_index()\n",
    "    )\n",
    "\n",
    "    # Add absolute start/end for the aggregated arm segment\n",
    "    arm_agg = arm_agg.merge(chrom_features_df[['chromosome', 'chromosome_absolute_start']], on='chromosome', how='left')\n",
    "    arm_agg['arm_absolute_start'] = arm_agg['chromosome_absolute_start'] + arm_agg['arm_start']\n",
    "    arm_agg['arm_absolute_end'] = arm_agg['chromosome_absolute_start'] + arm_agg['arm_end']\n",
    "\n",
    "    return arm_agg.drop(columns=['chromosome_absolute_start'], errors='ignore').dropna(subset=['log2'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2731c18419e474d9",
   "metadata": {},
   "source": [
    "def _plot_ngs_scatter(ax, ngs_df_case):\n",
    "    \"\"\"Plots individual NGS bins. Colors based on log2 value (gain/loss/neutral).\"\"\"\n",
    "    if ngs_df_case.empty or 'log2' not in ngs_df_case.columns or 'absolute_start' not in ngs_df_case.columns:\n",
    "        return\n",
    "\n",
    "    log2_values = pd.to_numeric(ngs_df_case['log2'], errors='coerce').clip(-PLOT_Y_LIM, PLOT_Y_LIM)\n",
    "    abs_pos = ngs_df_case['absolute_start']\n",
    "\n",
    "    # Calculate alpha based on z-score of log2 values\n",
    "    if len(log2_values) > 1:  # zscore needs at least 2 points\n",
    "        # zscore returns a numpy array if input is a Series, re-index to match original\n",
    "        abs_z = np.abs(zscore(log2_values.to_numpy()))\n",
    "        calculated_alphas = np.clip((abs_z / 3) ** 2.25, 0.01, 1.0)\n",
    "        alphas = pd.Series(calculated_alphas, index=log2_values.index)\n",
    "    else:\n",
    "        alphas = pd.Series([0.5], index=log2_values.index)  # Default alpha for a single point\n",
    "\n",
    "    # Define colors\n",
    "    color_gain = 'tab:orange'\n",
    "    color_loss = 'tab:blue'\n",
    "    color_neutral = 'grey'\n",
    "\n",
    "    # Create masks for plotting, excluding NaNs from these categories\n",
    "    mask_gain = (log2_values > 1e-6)  # Use a small epsilon for > 0\n",
    "    mask_loss = (log2_values < -1e-6)  # Use a small epsilon for < 0\n",
    "    mask_neutral = np.isclose(log2_values, 0, atol=1e-6)\n",
    "\n",
    "    # Plot gains\n",
    "    if mask_gain.any():\n",
    "        ax.scatter(abs_pos[mask_gain], log2_values[mask_gain],\n",
    "                   color=color_gain, alpha=alphas[mask_gain], s=2)\n",
    "\n",
    "    # Plot losses\n",
    "    if mask_loss.any():\n",
    "        ax.scatter(abs_pos[mask_loss], log2_values[mask_loss],\n",
    "                   color=color_loss, alpha=alphas[mask_loss], s=2)\n",
    "\n",
    "    # Plot neutral points\n",
    "    if mask_neutral.any():\n",
    "        ax.scatter(abs_pos[mask_neutral], log2_values[mask_neutral],\n",
    "                   color=color_neutral, alpha=alphas[mask_neutral], s=2)\n",
    "\n",
    "\n",
    "def _plot_arm_means(ax, df_aggregated_case, color, linestyle, linewidth, label_text_prefix):\n",
    "    if df_aggregated_case.empty or 'log2' not in df_aggregated_case.columns:\n",
    "        return\n",
    "\n",
    "    start_col = 'arm_absolute_start' if 'arm_absolute_start' in df_aggregated_case.columns else 'absolute_start'\n",
    "    end_col = 'arm_absolute_end' if 'arm_absolute_end' in df_aggregated_case.columns else 'absolute_end'\n",
    "\n",
    "    if not all(c in df_aggregated_case.columns for c in [start_col, end_col, 'log2']):\n",
    "        return\n",
    "\n",
    "    for idx, row in df_aggregated_case.reset_index().iterrows():\n",
    "        if pd.notna(row['log2']) and pd.notna(row[start_col]) and pd.notna(row[end_col]):\n",
    "            ax.plot(\n",
    "                [row[start_col], row[end_col]],\n",
    "                [row['log2'], row['log2']],\n",
    "                color=color,\n",
    "                linestyle=linestyle,\n",
    "                linewidth=linewidth,\n",
    "                label=f'{label_text_prefix}' if idx == 0 else None  # Label only first segment\n",
    "            )\n",
    "\n",
    "\n",
    "def _plot_gene_labels(ax, gene_reps_case):\n",
    "    if gene_reps_case.empty or not all(c in gene_reps_case.columns for c in ['absolute_position', 'log2', 'gene']):\n",
    "        return\n",
    "\n",
    "    valid_gene_reps = gene_reps_case.dropna(subset=['absolute_position', 'log2', 'gene'])\n",
    "    if valid_gene_reps.empty: return\n",
    "\n",
    "    ax.scatter(\n",
    "        valid_gene_reps['absolute_position'],\n",
    "        valid_gene_reps['log2'],\n",
    "        color='black', s=4\n",
    "    )\n",
    "    for _, row in valid_gene_reps.iterrows():\n",
    "        y, name = row['log2'], row['gene']\n",
    "\n",
    "        offset = 0.15 if y > 0 else -0.15\n",
    "        if abs(y) > PLOT_Y_LIM * 0.75:\n",
    "            offset = -1 * offset\n",
    "        va = 'bottom' if offset > 0 else 'top'\n",
    "\n",
    "        ax.text(\n",
    "            row['absolute_position'],\n",
    "            y + offset,\n",
    "            name,\n",
    "            fontsize=8,\n",
    "            ha='center',\n",
    "            va=va,\n",
    "            rotation=90\n",
    "        )\n",
    "\n",
    "\n",
    "def draw_cnv_plot(case_info, df_ngs_case, df_ngs_agg, df_epic_agg, df_gene_reps,\n",
    "                  df_chroms, arm_map_df):\n",
    "    case_n_number = case_info['case_n_number']\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Use the style-specific helper functions\n",
    "    _plot_ngs_scatter(ax, df_ngs_case)\n",
    "    _plot_arm_means(ax, df_ngs_agg, 'purple', '-', 1.5, 'average cnr (ngs sample)')\n",
    "    _plot_arm_means(ax, df_epic_agg, 'purple', '--', 1.0, 'average cnr (epic reference)')\n",
    "    _plot_gene_labels(ax, df_gene_reps)\n",
    "\n",
    "    # Axis lines and ticks\n",
    "    ax.axhline(0, color='grey', linewidth=0.5)\n",
    "\n",
    "    if not df_chroms.empty and all(\n",
    "            c in df_chroms.columns for c in ['chromosome_absolute_start', 'length', 'chromosome']):\n",
    "        chrom_starts = df_chroms['chromosome_absolute_start']\n",
    "        ax.vlines(chrom_starts, -PLOT_Y_LIM, PLOT_Y_LIM,\n",
    "                  color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Draw vertical lines at p/q arm boundaries\n",
    "        if not arm_map_df.empty and 'arm_abs_end' in arm_map_df.columns:\n",
    "            # The end of the 'p' arm is the centromere / p-q boundary\n",
    "            pq_boundaries = arm_map_df.loc[arm_map_df['arm'] == 'p', 'arm_abs_end']\n",
    "            if not pq_boundaries.empty:\n",
    "                ax.vlines(pq_boundaries, -PLOT_Y_LIM, PLOT_Y_LIM,\n",
    "                          color='grey', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        mids = chrom_starts + df_chroms['length'] / 2\n",
    "        ax.set_xticks(mids)\n",
    "        ax.set_xticklabels(df_chroms['chromosome'].astype(str), rotation=90)\n",
    "\n",
    "    xlim_max = df_chroms['chromosome_absolute_start'].iloc[-1] + df_chroms['length'].iloc[-1]\n",
    "\n",
    "    ax.set(\n",
    "        xlim=(0, xlim_max),\n",
    "        ylim=(-PLOT_Y_LIM, PLOT_Y_LIM),\n",
    "        xlabel='genomic position by chromosome',\n",
    "        ylabel='copy number deviation (log2)'\n",
    "    )\n",
    "\n",
    "    plt.suptitle(f'CNV profile of {case_n_number} from NGS sample vs. EPIC reference', fontsize=14)\n",
    "    plt.title(\n",
    "        f\"{case_info.get('sex', 'N/A')} (age {case_info.get('age', 'N/A')}), {case_info.get('diagnosis', 'N/A')}\",\n",
    "        fontsize=10, pad=6\n",
    "    )\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = PLOT_OUTPUT_DIR / 'scatter' / f\"ngs_scatter_{case_n_number.replace('/', '_')}.png\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    print(f\"Saved plot: {fname}\")\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9935d84fc4a6234",
   "metadata": {},
   "source": [
    "def calculate_arm_correlations(ngs_aggregated_df, epic_aggregated_df):\n",
    "    \"\"\"Calculates Pearson correlation between NGS and EPIC log2 values per arm.\"\"\"\n",
    "    if ngs_aggregated_df.empty or epic_aggregated_df.empty:\n",
    "        return pd.DataFrame(columns=['chromosome', 'arm', 'pearson_r', 'p_value', 'n_samples'])\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        ngs_aggregated_df[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        epic_aggregated_df[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        on=['case_n_number', 'chromosome', 'segment_arm'],\n",
    "        suffixes=('_ngs', '_epic'),\n",
    "        how='inner'  # Only cases/arms present in both\n",
    "    )\n",
    "    if merged_df.empty: return pd.DataFrame(columns=['chromosome', 'arm', 'pearson_r', 'p_value', 'n_samples'])\n",
    "\n",
    "    corr_results = []\n",
    "    for (chrom, arm), group in merged_df.groupby(['chromosome', 'segment_arm']):\n",
    "        if len(group) >= 3:  # Pearson r needs at least 2, but more is better\n",
    "            r, p = pearsonr(group['log2_ngs'], group['log2_epic'])\n",
    "        else:\n",
    "            r, p = np.nan, np.nan\n",
    "        corr_results.append({'chromosome': chrom, 'arm': arm, 'pearson_r': r, 'p_value': p, 'n_samples': len(group)})\n",
    "\n",
    "    return pd.DataFrame(corr_results).sort_values(['chromosome', 'arm']).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "718f7092bf4888e5",
   "metadata": {},
   "source": [
    "def plot_correlation_scatter(merged_correlation_df, arm_corr_stats_df):\n",
    "    \"\"\"Plots scatter of NGS vs EPIC log2 values, faceted by chromosome, colored by arm, with correlation annotations.\"\"\"\n",
    "    if merged_correlation_df.empty:\n",
    "        print(\"Merged data for correlation plot is empty. Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data=merged_correlation_df, x='log2_ngs', y='log2_epic',\n",
    "        col='chromosome', hue='segment_arm', kind='scatter', palette=ARM_COLORS,\n",
    "        col_wrap=6, height=2, aspect=1, s=20, alpha=0.7,\n",
    "        facet_kws={'sharex': True, 'sharey': True}\n",
    "    )\n",
    "\n",
    "    for ax, chrom_name in zip(g.axes.flat, g.col_names):\n",
    "        if pd.isna(chrom_name): continue  # Skip if chrom_name is NaN (can happen if few chromosomes)\n",
    "        chrom_corrs_on_plot = arm_corr_stats_df[arm_corr_stats_df['chromosome'] == chrom_name]\n",
    "\n",
    "        for arm_label, color in ARM_COLORS.items():\n",
    "            if arm_label is None: continue  # Skip None arm for text annotation\n",
    "            arm_data_for_text = chrom_corrs_on_plot[chrom_corrs_on_plot['arm'] == arm_label]\n",
    "\n",
    "            if not arm_data_for_text.empty and not pd.isna(arm_data_for_text.iloc[0]['pearson_r']):\n",
    "                r_val = arm_data_for_text.iloc[0]['pearson_r']\n",
    "                p_val = arm_data_for_text.iloc[0]['p_value']\n",
    "\n",
    "                text_label = f'r({arm_label})={r_val:.2f}'\n",
    "                x_pos, ha = (0.05, 'left') if arm_label == 'p' else (0.95, 'right')\n",
    "\n",
    "                ax.text(x_pos, 0.95, text_label, transform=ax.transAxes, color=color,\n",
    "                        ha=ha, va='top', fontsize=8,\n",
    "                        bbox=dict(facecolor='#d4edda', alpha=0.6, edgecolor='none', pad=0.2))\n",
    "\n",
    "    g.set_axis_labels('ngs cn ratio (log2)', 'epic cn ratio (log2)', fontsize=10)\n",
    "    g.fig.subplots_adjust(top=0.92)  # Adjust top for suptitle\n",
    "    g.fig.suptitle('NGS vs EPIC: copy number correlation by chromosome and arm', fontsize=14)\n",
    "\n",
    "    fname = PLOT_OUTPUT_DIR / 'correlation' / \"ngs_epic_arm_correlation.png\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    print(f\"Saved correlation plot: {fname}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d71ba9e386f8c183",
   "metadata": {},
   "source": [
    "cases_df = load_and_preprocess_cases(CASES_FILE_PATH)\n",
    "cases_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e12a7a062f4f6e2d",
   "metadata": {},
   "source": [
    "cytoband_df = load_and_preprocess_cytoband(CYTOBAND_FILE_PATH)\n",
    "cytoband_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0c5150170cba5ac",
   "metadata": {},
   "source": [
    "genes_df = load_and_preprocess_relevant_genes(RELEVANT_GENES_FILE_PATH)\n",
    "genes_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ed285c318a30383",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"Base Dir: {BASE_DATA_DIR.resolve()}, Plot Dir: {PLOT_OUTPUT_DIR.resolve()}, Corr. Plot Dir: {PLOT_OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "chroms_df, chrom_map = pd.DataFrame(), {}\n",
    "arm_map_df, arm_lookup_table = pd.DataFrame(), pd.DataFrame()\n",
    "gene_trees = {}\n",
    "\n",
    "if not cytoband_df.empty:\n",
    "    chroms_df, chrom_map = calculate_chromosome_features(cytoband_df)\n",
    "    arm_map_df = create_arm_mapping_df(cytoband_df, chrom_map)\n",
    "    arm_lookup_table = create_arm_lookup_table(arm_map_df)\n",
    "if not genes_df.empty:\n",
    "    gene_trees = build_gene_interval_trees(genes_df)\n",
    "gene_trees"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d45cbf9af1626940",
   "metadata": {},
   "source": [
    "# Process EPIC data - both raw and segments\n",
    "epic_raw_df = pd.DataFrame()\n",
    "epic_segments_df = pd.DataFrame()\n",
    "epic_df_aggregated_all = pd.DataFrame()\n",
    "\n",
    "if not cases_df.empty and not arm_lookup_table.empty and not arm_map_df.empty:\n",
    "    print(\"=== Loading EPIC data ===\")\n",
    "\n",
    "    # Load EPIC raw data from IGV files\n",
    "    print(\"\\n--- Loading EPIC raw data from IGV files ---\")\n",
    "    igv_dir = BASE_DATA_DIR / 'epic/igv'\n",
    "    if igv_dir.exists():\n",
    "        igv_files = list(igv_dir.glob('*.igv'))\n",
    "        print(f\"Found {len(igv_files)} IGV files in {igv_dir}\")\n",
    "    else:\n",
    "        print(f\"Warning: IGV directory does not exist: {igv_dir}\")\n",
    "\n",
    "    epic_raw_df = load_combine_genomic_data(cases_df, BASE_DATA_DIR, 'epic', 'raw', 'sentrix_id')\n",
    "    print(f\"EPIC raw data loaded: {epic_raw_df.shape}\")\n",
    "\n",
    "    # Load EPIC segments from SEG files  \n",
    "    print(\"\\n--- Loading EPIC segments from SEG files ---\")\n",
    "    seg_dir = BASE_DATA_DIR / 'epic/seg'\n",
    "    if seg_dir.exists():\n",
    "        seg_files = list(seg_dir.glob('*.seg'))\n",
    "        print(f\"Found {len(seg_files)} SEG files in {seg_dir}\")\n",
    "    else:\n",
    "        print(f\"Warning: SEG directory does not exist: {seg_dir}\")\n",
    "\n",
    "    epic_segments_df = load_combine_genomic_data(cases_df, BASE_DATA_DIR, 'epic', 'segments', 'sentrix_id')\n",
    "    print(f\"EPIC segments loaded: {epic_segments_df.shape}\")\n",
    "\n",
    "    # Process EPIC segments for arm aggregation (using segments for correlation analysis)\n",
    "    if not epic_segments_df.empty:\n",
    "        print(\"\\n--- Processing EPIC segments for arm aggregation ---\")\n",
    "        epic_classified = add_segment_arm_classification(epic_segments_df.copy(), arm_lookup_table)\n",
    "        print(f\"EPIC segments classified: {epic_classified.shape}\")\n",
    "\n",
    "        epic_df_aggregated_all = calculate_arm_log2_from_segments(epic_classified, arm_map_df, 'sentrix_id')\n",
    "        print(f\"EPIC aggregated data: {epic_df_aggregated_all.shape}\")\n",
    "    else:\n",
    "        print(\"No EPIC segments loaded - check if SEG files exist and have correct naming\")\n",
    "\n",
    "print(f\"\\nEPIC data summary:\")\n",
    "print(f\"- Raw data (IGV): {epic_raw_df.shape}\")\n",
    "print(f\"- Segments (SEG): {epic_segments_df.shape}\")\n",
    "print(f\"- Aggregated: {epic_df_aggregated_all.shape}\")\n",
    "\n",
    "epic_df_aggregated_all"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "399cb51b0c602df6",
   "metadata": {},
   "source": [
    "ngs_raw_df = pd.DataFrame()  # Raw CNR data (for scatter plots)\n",
    "ngs_segments_df = pd.DataFrame()  # CNS segments (for heatmaps and analysis)\n",
    "ngs_df_processed_full = pd.DataFrame()  # Processed raw data (for scatter plots)\n",
    "ngs_arm_aggregated_all = pd.DataFrame()  # Arm-level aggregation (for correlation)\n",
    "ngs_gene_reps_all = pd.DataFrame()  # Gene-level aggregation (for gene labels)\n",
    "\n",
    "if not cases_df.empty:\n",
    "    print(\"=== Loading NGS data ===\")\n",
    "\n",
    "    # Load NGS raw data from CNR files\n",
    "    print(\"\\n--- Loading NGS raw data from CNR files ---\")\n",
    "    cnr_dir = BASE_DATA_DIR / 'ngs/cnr'\n",
    "    if cnr_dir.exists():\n",
    "        cnr_files = list(cnr_dir.glob('*.cnr'))\n",
    "        print(f\"Found {len(cnr_files)} CNR files in {cnr_dir}\")\n",
    "    else:\n",
    "        print(f\"Warning: CNR directory does not exist: {cnr_dir}\")\n",
    "\n",
    "    ngs_raw_df = load_combine_genomic_data(cases_df, BASE_DATA_DIR, 'ngs', 'raw', 'barcode')\n",
    "    print(f\"NGS raw data loaded: {ngs_raw_df.shape}\")\n",
    "\n",
    "    # Load NGS segments from CNS files\n",
    "    print(\"\\n--- Loading NGS segments from CNS files ---\")\n",
    "    cns_dir = BASE_DATA_DIR / 'ngs/cns'\n",
    "    if cns_dir.exists():\n",
    "        cns_files = list(cns_dir.glob('*.cns'))\n",
    "        print(f\"Found {len(cns_files)} CNS files in {cns_dir}\")\n",
    "    else:\n",
    "        print(f\"Warning: CNS directory does not exist: {cns_dir}\")\n",
    "\n",
    "    ngs_segments_df = load_combine_genomic_data(cases_df, BASE_DATA_DIR, 'ngs', 'segments', 'barcode')\n",
    "    print(f\"NGS segments loaded: {ngs_segments_df.shape}\")\n",
    "\n",
    "    # Process NGS raw data for scatter plots\n",
    "    if not ngs_raw_df.empty:\n",
    "        print(\"\\n--- Processing NGS raw data ---\")\n",
    "        ngs_curr = ngs_raw_df.copy()\n",
    "\n",
    "        # Add absolute genomic positions if chromosome map is available\n",
    "        if chrom_map:\n",
    "            ngs_curr = prep_ngs_agg(ngs_curr, chrom_map)\n",
    "\n",
    "        # Classify each segment/bin by chromosome arm (p/q/spanning) if lookup table is available\n",
    "        if not arm_lookup_table.empty:\n",
    "            ngs_curr = add_segment_arm_classification(ngs_curr, arm_lookup_table)\n",
    "\n",
    "        # Annotate with relevant genes and aggregate to gene level if gene trees are available\n",
    "        if gene_trees:\n",
    "            ngs_curr = annotate_segments_with_genes(ngs_curr, gene_trees, genes_df)\n",
    "            ngs_gene_reps_all = aggregate_data_by_gene(ngs_curr)\n",
    "\n",
    "        # Aggregate NGS points to chromosome arms for correlation/plotting if possible\n",
    "        if not chroms_df.empty and 'segment_arm' in ngs_curr.columns:\n",
    "            ngs_arm_aggregated_all = agg_ngs_points_to_arms(ngs_curr, chroms_df)\n",
    "\n",
    "        # Store the fully processed NGS DataFrame\n",
    "        ngs_df_processed_full = ngs_curr\n",
    "\n",
    "    # Process NGS segments for additional analysis if needed\n",
    "    if not ngs_segments_df.empty:\n",
    "        print(\"\\n--- Processing NGS segments ---\")\n",
    "        # Add absolute genomic positions for segments\n",
    "        if chrom_map:\n",
    "            ngs_segments_df = prep_ngs_agg(ngs_segments_df, chrom_map)\n",
    "\n",
    "        # Classify segments by chromosome arm\n",
    "        if not arm_lookup_table.empty:\n",
    "            ngs_segments_df = add_segment_arm_classification(ngs_segments_df, arm_lookup_table)\n",
    "\n",
    "print(f\"\\nNGS data summary:\")\n",
    "print(f\"- Raw data (CNR): {ngs_raw_df.shape}\")\n",
    "print(f\"- Segments (CNS): {ngs_segments_df.shape}\")\n",
    "print(f\"- Processed raw: {ngs_df_processed_full.shape}\")\n",
    "print(f\"- Arm aggregated: {ngs_arm_aggregated_all.shape}\")\n",
    "print(f\"- Gene reps: {ngs_gene_reps_all.shape}\")\n",
    "\n",
    "# Show the processed NGS DataFrame for inspection\n",
    "ngs_df_processed_full"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91074dcc86d385c9",
   "metadata": {},
   "source": [
    "# Generate CNV plots for each case\n",
    "if not cases_df.empty and not ngs_df_processed_full.empty:\n",
    "    print(f\"\\n--- Generating CNV plots for {len(cases_df)} cases ---\")\n",
    "    print(f\"EPIC data shape: {epic_df_aggregated_all.shape}\")\n",
    "    print(f\"NGS arm aggregated shape: {ngs_arm_aggregated_all.shape}\")\n",
    "    print(f\"NGS gene reps shape: {ngs_gene_reps_all.shape}\")\n",
    "\n",
    "    for _, case_r in cases_df.iterrows():\n",
    "        cnum = case_r['case_n_number']\n",
    "        ngs_c = ngs_df_processed_full[ngs_df_processed_full['case_n_number'] == cnum].copy()\n",
    "        ngs_agg_c = ngs_arm_aggregated_all[ngs_arm_aggregated_all[\n",
    "                                               'case_n_number'] == cnum].copy() if not ngs_arm_aggregated_all.empty else pd.DataFrame()\n",
    "        epic_agg_c = epic_df_aggregated_all[epic_df_aggregated_all[\n",
    "                                                'case_n_number'] == cnum].copy() if not epic_df_aggregated_all.empty else pd.DataFrame()\n",
    "        gene_reps_c = ngs_gene_reps_all[\n",
    "            ngs_gene_reps_all['case_n_number'] == cnum].copy() if not ngs_gene_reps_all.empty else pd.DataFrame()\n",
    "\n",
    "        if ngs_c.empty and ngs_agg_c.empty and epic_agg_c.empty and gene_reps_c.empty:\n",
    "            print(f\"Skipping plot for {cnum}: No data.\")\n",
    "            continue\n",
    "        draw_cnv_plot(case_r, ngs_c, ngs_agg_c, epic_agg_c, gene_reps_c, chroms_df, arm_map_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c531e63c61a8b16d",
   "metadata": {},
   "source": [
    "# Calculate and plot correlations\n",
    "if not ngs_arm_aggregated_all.empty and not epic_df_aggregated_all.empty:\n",
    "    print(\"\\n--- Calculating and plotting NGS vs EPIC arm correlations ---\")\n",
    "    arm_correlations_df = calculate_arm_correlations(ngs_arm_aggregated_all, epic_df_aggregated_all)\n",
    "    print(\"Arm correlation:\\n\", arm_correlations_df)\n",
    "\n",
    "    # Need the merged df for plotting points (not just stats)\n",
    "    merged_for_plot = pd.merge(\n",
    "        ngs_arm_aggregated_all[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        epic_df_aggregated_all[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        on=['case_n_number', 'chromosome', 'segment_arm'],\n",
    "        suffixes=('_ngs', '_epic'), how='inner'\n",
    "    )\n",
    "    plot_correlation_scatter(merged_for_plot, arm_correlations_df)\n",
    "else:\n",
    "    print(\"Skipping correlation analysis: Aggregated NGS or EPIC data is missing.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1da6c15",
   "metadata": {},
   "source": [
    "def plot_cnv_heatmap_new(ngs_data, epic_data, cases_info, chrom_info, title, ax,\n",
    "                     show_tumor_type_axis=True, group_by_column=None):\n",
    "    \"\"\"\n",
    "    Generates a CNV heatmap with a robust, unified logic for all plotting scenarios.\n",
    "    - If group_by_column is provided (e.g., 'tumor_type'), it creates visually\n",
    "      distinct sub-diagrams for each group with headers and dividers.\n",
    "      IMPORTANT: cases_info MUST be sorted by the group_by_column for this to work.\n",
    "    \"\"\"\n",
    "    # --- Setup genomic coordinate system ---\n",
    "    chrom_starts = chrom_info.set_index('chromosome')['chromosome_absolute_start']\n",
    "    chrom_sizes = chrom_info.set_index('chromosome')['length']\n",
    "    chrom_ends = chrom_starts + chrom_sizes\n",
    "    total_genome_length = chrom_ends.max()\n",
    "    bin_size = 1_000_000\n",
    "    total_bins = int(np.ceil(total_genome_length / bin_size))\n",
    "\n",
    "    # --- Determine mode and setup dimensions ---\n",
    "    single_row_mode = epic_data.empty or ngs_data.empty\n",
    "    rows_per_patient = 1 if single_row_mode else 2\n",
    "    num_patients = len(cases_info)\n",
    "\n",
    "    # --- Calculate total rows needed, including gaps for headers ---\n",
    "    header_gap_size = 2 # Space for the header and visual separation\n",
    "    num_groups = 0\n",
    "    if group_by_column and group_by_column in cases_info.columns and num_patients > 0:\n",
    "        num_groups = cases_info[group_by_column].nunique()\n",
    "    total_rows = (num_patients * rows_per_patient) + (num_groups * header_gap_size)\n",
    "    heatmap_array = np.full((total_rows, total_bins), np.nan)\n",
    "\n",
    "    # --- Unified Loop to Populate Data and Store Tick Positions ---\n",
    "    y_ticks_positions = []\n",
    "    y_tick_labels = []\n",
    "    current_row = 0\n",
    "    last_group_id = None\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        case_info = cases_info.iloc[i]\n",
    "\n",
    "        if group_by_column:\n",
    "            current_group_id = case_info[group_by_column]\n",
    "            # If a new group starts, create the header section\n",
    "            if current_group_id != last_group_id:\n",
    "                # Add a thick divider line above the header, but not for the very first group\n",
    "                if last_group_id is not None:\n",
    "                    ax.axhline(y=current_row - 0.5, color='black', linewidth=1.5)\n",
    "\n",
    "                # Place the header text in the middle of the dedicated gap space\n",
    "                header_y_pos = current_row + (header_gap_size / 2) - 0.5\n",
    "                ax.text(0, header_y_pos, current_group_id,\n",
    "                        ha='left', va='center',\n",
    "                        fontsize=9, fontweight='bold', color='black')\n",
    "\n",
    "                # Advance the row cursor to create the gap\n",
    "                current_row += header_gap_size\n",
    "                last_group_id = current_group_id\n",
    "\n",
    "        # Store positions for patient labels\n",
    "        y_ticks_positions.append(current_row + (rows_per_patient / 2 - 0.5))\n",
    "        y_tick_labels.append('P' + str(case_info['patient_id']))\n",
    "\n",
    "        # Populate heatmap data for the current patient\n",
    "        case_id = case_info['case_n_number']\n",
    "        if single_row_mode:\n",
    "            data_source = ngs_data if epic_data.empty else epic_data\n",
    "            case_data = data_source[data_source['case_n_number'] == case_id]\n",
    "            for _, seg in case_data.iterrows():\n",
    "                if seg['chromosome'] in chrom_starts.index:\n",
    "                    abs_start = chrom_starts[seg['chromosome']] + seg['start']\n",
    "                    abs_end = chrom_starts[seg['chromosome']] + seg['end']\n",
    "                    s_bin, e_bin = int(abs_start / bin_size), int(np.ceil(abs_end / bin_size))\n",
    "                    heatmap_array[current_row, s_bin:e_bin] = seg['log2']\n",
    "        else: # Two-row mode\n",
    "            epic_row_idx, ngs_row_idx = current_row, current_row + 1\n",
    "            if not epic_data.empty:\n",
    "                epic_case_data = epic_data[epic_data['case_n_number'] == case_id]\n",
    "                for _, seg in epic_case_data.iterrows():\n",
    "                    if seg['chromosome'] in chrom_starts.index:\n",
    "                        abs_start = chrom_starts[seg['chromosome']] + seg['start']\n",
    "                        abs_end = chrom_starts[seg['chromosome']] + seg['end']\n",
    "                        s_bin, e_bin = int(abs_start / bin_size), int(np.ceil(abs_end / bin_size))\n",
    "                        heatmap_array[epic_row_idx, s_bin:e_bin] = seg['log2']\n",
    "            if not ngs_data.empty:\n",
    "                ngs_case_data = ngs_data[ngs_data['case_n_number'] == case_id]\n",
    "                for _, seg in ngs_case_data.iterrows():\n",
    "                    if seg['chromosome'] in chrom_starts.index:\n",
    "                        abs_start = chrom_starts[seg['chromosome']] + seg['start']\n",
    "                        abs_end = chrom_starts[seg['chromosome']] + seg['end']\n",
    "                        s_bin, e_bin = int(abs_start / bin_size), int(np.ceil(abs_end / bin_size))\n",
    "                        heatmap_array[ngs_row_idx, s_bin:e_bin] = seg['log2']\n",
    "\n",
    "        # Draw Horizontal Lines Within the Loop\n",
    "        if not single_row_mode:\n",
    "            ax.axhline(y=current_row + 0.5, color='grey', linestyle=':', linewidth=0.5)\n",
    "\n",
    "        # Always draw a thin line between patients within a group\n",
    "        if i < num_patients - 1:\n",
    "             # Check if the next patient is in the same group\n",
    "            if not group_by_column or (cases_info.iloc[i+1][group_by_column] == case_info[group_by_column]):\n",
    "                ax.axhline(y=current_row + rows_per_patient - 0.5, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "        current_row += rows_per_patient\n",
    "\n",
    "    # --- Plot the final matrix ---\n",
    "    cmap = plt.get_cmap('RdBu_r'); cmap.set_bad(color='white')\n",
    "    norm = mcolors.Normalize(vmin=-2, vmax=2)\n",
    "    clipped_data = np.clip(heatmap_array, -2, 2)\n",
    "    ax.imshow(clipped_data, cmap=cmap, norm=norm, aspect='auto', interpolation='none')\n",
    "\n",
    "    # --- Configure axes ---\n",
    "    ax.grid(False)\n",
    "    ax.set_yticks(y_ticks_positions)\n",
    "    ax.set_yticklabels(y_tick_labels, fontsize=8)\n",
    "\n",
    "    chrom_mid_bins = (chrom_starts + chrom_sizes / 2) / bin_size\n",
    "    ax.set_xticks(chrom_mid_bins)\n",
    "    ax.set_xticklabels(['chr' + str(c) for c in chrom_mid_bins.index], rotation=90, fontsize=8)\n",
    "\n",
    "    if show_tumor_type_axis:\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylim(ax.get_ylim())\n",
    "        ax2.set_yticks(y_ticks_positions)\n",
    "        tumor_labels = cases_info['tumor_type'].tolist()\n",
    "        ax2.set_yticklabels(tumor_labels, fontsize=8)\n",
    "        ax2.grid(False)\n",
    "        ax2.tick_params(axis='y', colors='black', direction='out')\n",
    "        for spine in ax2.spines.values():\n",
    "            spine.set_edgecolor('black')\n",
    "        unique_tumor_types = sorted(list(set(tumor_labels)))\n",
    "        cmap_tumor = plt.get_cmap('Dark2', len(unique_tumor_types))\n",
    "        tumor_type_to_color = {tt: cmap_tumor(i) for i, tt in enumerate(unique_tumor_types)}\n",
    "        for tick_label, tumor_type in zip(ax2.get_yticklabels(), tumor_labels):\n",
    "            tick_label.set_color(tumor_type_to_color.get(tumor_type, 'black'))\n",
    "        ax2.set_ylabel('Tumor type', fontsize=10)\n",
    "\n",
    "    ax.tick_params(axis='y', colors='black', direction='out')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "    chrom_end_bins = chrom_ends / bin_size\n",
    "    for end_bin in chrom_end_bins.values[:-1]:\n",
    "        boundary_pos = np.ceil(end_bin) - 0.5\n",
    "        ax.axvline(x=boundary_pos, color='black', linestyle='--', linewidth=0.25)\n",
    "\n",
    "    ax.set_xlim(-0.5, total_bins - 0.5)\n",
    "    ax.set_ylim(total_rows - 0.5, -0.5) # Set ylim explicitly to match total rows\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('Chromosome', fontsize=10)\n",
    "    ax.set_ylabel('Sample', fontsize=10)\n",
    "\n",
    "    return ax"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_cnv_heatmap(ngs_data, epic_data, cases_info, chrom_info, title, ax):\n",
    "    # ... (Setup code is the same) ...\n",
    "    # 1. SETUP & 2. POPULATE MATRIX (This part is correct)\n",
    "    chrom_starts = chrom_info.set_index('chromosome')['chromosome_absolute_start']\n",
    "    chrom_sizes = chrom_info.set_index('chromosome')['length']\n",
    "    chrom_ends = chrom_starts + chrom_sizes\n",
    "    total_genome_length = chrom_ends.max()\n",
    "    bin_size = 1_000_000\n",
    "    total_bins = int(np.ceil(total_genome_length / bin_size))\n",
    "    patient_ids_subset = cases_info['patient_id'].tolist()\n",
    "    num_patients = len(patient_ids_subset)\n",
    "    heatmap_array = np.full((num_patients * 2, total_bins), np.nan)\n",
    "    patient_to_case_map = cases_info.set_index('patient_id')['case_n_number'].to_dict()\n",
    "    for i, patient_id in enumerate(patient_ids_subset):\n",
    "        case_id = patient_to_case_map.get(patient_id)\n",
    "        if case_id is None: continue\n",
    "        epic_row_idx, ngs_row_idx = i * 2, i * 2 + 1\n",
    "        if not epic_data.empty:\n",
    "            epic_case_data = epic_data[epic_data['case_n_number'] == case_id]\n",
    "            for _, seg in epic_case_data.iterrows():\n",
    "                if seg['chromosome'] not in chrom_starts.index: continue\n",
    "                abs_start = chrom_starts[seg['chromosome']] + seg['start']\n",
    "                abs_end = chrom_starts[seg['chromosome']] + seg['end']\n",
    "                s_bin, e_bin = int(abs_start / bin_size), int(np.ceil(abs_end / bin_size))\n",
    "                heatmap_array[epic_row_idx, s_bin:e_bin] = seg['log2']\n",
    "        if not ngs_data.empty:\n",
    "            ngs_case_data = ngs_data[ngs_data['case_n_number'] == case_id]\n",
    "            for _, seg in ngs_case_data.iterrows():\n",
    "                if seg['chromosome'] not in chrom_starts.index: continue\n",
    "                abs_start = chrom_starts[seg['chromosome']] + seg['start']\n",
    "                abs_end = chrom_starts[seg['chromosome']] + seg['end']\n",
    "                s_bin, e_bin = int(abs_start / bin_size), int(np.ceil(abs_end / bin_size))\n",
    "                heatmap_array[ngs_row_idx, s_bin:e_bin] = seg['log2']\n",
    "\n",
    "    # 3. PLOT THE MATRIX\n",
    "    cmap = plt.get_cmap('RdBu_r'); cmap.set_bad(color='#fbfbfb')\n",
    "    norm = mcolors.Normalize(vmin=-2, vmax=2)\n",
    "    clipped_data = np.clip(heatmap_array, -2, 2)\n",
    "    ax.imshow(clipped_data, cmap=cmap, norm=norm, aspect='auto', interpolation='none')\n",
    "\n",
    "    # 4. CONFIGURE AXES AND LABELS\n",
    "    ax.grid(False)\n",
    "    y_ticks = [i * 2 + 0.5 for i in range(num_patients)]\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(['P' + str(pid) for pid in patient_ids_subset], fontsize=8)\n",
    "\n",
    "    chrom_mid_bins = (chrom_starts + chrom_sizes / 2) / bin_size\n",
    "    ax.set_xticks(chrom_mid_bins)\n",
    "    ax.set_xticklabels(['chr' + str(c) for c in chrom_mid_bins.index], rotation=90, fontsize=8)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(ax.get_ylim())\n",
    "    ax2.set_yticks(y_ticks)\n",
    "\n",
    "    tumor_labels = cases_info['tumor_type'].tolist()[::-1]\n",
    "    ax2.set_yticklabels(tumor_labels, fontsize=8)\n",
    "\n",
    "    ax2.grid(False)\n",
    "    ax.tick_params(axis='y', colors='black', direction='out')\n",
    "    ax2.tick_params(axis='y', colors='black', direction='out')\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "    unique_tumor_types = sorted(list(set(tumor_labels)))\n",
    "    cmap_tumor = plt.get_cmap('Dark2', len(unique_tumor_types))\n",
    "    tumor_type_to_color = {tt: cmap_tumor(i) for i, tt in enumerate(unique_tumor_types)}\n",
    "\n",
    "    for tick_label, tumor_type in zip(ax2.get_yticklabels(), tumor_labels):\n",
    "        tick_label.set_color(tumor_type_to_color.get(tumor_type, 'black'))\n",
    "\n",
    "    chrom_end_bins = chrom_ends / bin_size\n",
    "    for end_bin in chrom_end_bins.values[:-1]:\n",
    "        boundary_pos = np.ceil(end_bin) - 0.5\n",
    "        ax.axvline(x=boundary_pos, color='black', linestyle='--', linewidth=0.25)\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        ax.axhline(y=(i * 2) + 0.5, color='grey', linestyle='--',\n",
    "                    linewidth=0.15, antialiased=False)\n",
    "        if i < num_patients - 1:\n",
    "            ax.axhline(y=(i * 2) + 1.5, color='black', linestyle='-', linewidth=0.75)\n",
    "\n",
    "    ax.set_xlim(-0.5, total_bins - 0.5)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('Chromosome', fontsize=10)\n",
    "    ax.set_ylabel('Sample', fontsize=10)\n",
    "    ax2.set_ylabel('Tumor type', fontsize=10)\n",
    "\n",
    "    return ax"
   ],
   "id": "256ed68b79c3b65b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Generate a single CNV Heatmap for all cases ---\n",
    "\n",
    "if not cases_df.empty and not ngs_segments_df.empty and not epic_segments_df.empty:\n",
    "\n",
    "    print(f\"--- Generating a single CNV heatmap for all {len(cases_df)} cases ---\")\n",
    "\n",
    "    cases_sorted = cases_df.sort_values(['patient_id', 'tumor_type'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    cases_subset = cases_sorted\n",
    "\n",
    "    ngs_subset = ngs_segments_df\n",
    "    epic_subset = epic_segments_df\n",
    "\n",
    "    if ngs_subset.empty or epic_subset.empty:\n",
    "        print(f\"Skipping heatmap: Missing NGS or EPIC segment data.\")\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, len(cases_subset) * 0.175))\n",
    "\n",
    "        plot_cnv_heatmap(\n",
    "            ngs_data=ngs_subset,\n",
    "            epic_data=epic_subset,\n",
    "            cases_info=cases_subset,\n",
    "            chrom_info=chroms_df,\n",
    "            title='CNV heatmap from EPIC (upper row) vs. NGS (lower row)',\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fname = PLOT_OUTPUT_DIR / 'heatmap' / \"cnv_heatmap_all_cases.png\"\n",
    "        fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved heatmap: {fname}\")\n",
    "\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Skipping heatmap generation: Missing necessary data (cases, NGS segments, or EPIC segments).\")"
   ],
   "id": "c7eca597d84362dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"--- Starting batch heatmap generation ---\")\n",
    "\n",
    "if cases_df.empty or ngs_segments_df.empty or epic_segments_df.empty or chroms_df.empty:\n",
    "    print(\"Skipping heatmap generation: Missing necessary data.\")\n",
    "else:\n",
    "    print(\"\\n1. Generating one heatmap per tumor type...\")\n",
    "    unique_tumor_types = cases_df['tumor_type'].unique()\n",
    "    for tumor_type in unique_tumor_types:\n",
    "        cases_subset = cases_df[cases_df['tumor_type'] == tumor_type].sort_values('patient_id').reset_index(drop=True)\n",
    "        if cases_subset.empty: continue\n",
    "        fig, ax = plt.subplots(figsize=(12, len(cases_subset) * 0.3))\n",
    "        plot_cnv_heatmap(ngs_data=ngs_segments_df[ngs_segments_df['case_n_number'].isin(cases_subset['case_n_number'])],\n",
    "                         epic_data=epic_segments_df[epic_segments_df['case_n_number'].isin(cases_subset['case_n_number'])],\n",
    "                         cases_info=cases_subset, chrom_info=chroms_df, title=f'CNV Heatmap for {tumor_type}', ax=ax,\n",
    "                         show_tumor_type_axis=False)\n",
    "        safe_tumor_name = tumor_type.replace(' ', '_').replace('/', '_')\n",
    "        fname = PLOT_OUTPUT_DIR / 'heatmap' / f\"cnv_heatmap_{safe_tumor_name}.png\"\n",
    "        fname.parent.mkdir(parents=True, exist_ok=True); plt.savefig(fname, dpi=300, bbox_inches='tight'); plt.show(); plt.close(fig)\n",
    "\n",
    "    print(\"\\n2. Generating sub-diagram heatmaps for all EPIC and all NGS data...\")\n",
    "\n",
    "    cases_sorted_all = cases_df.sort_values(['patient_id', 'tumor_type']).reset_index(drop=True)\n",
    "\n",
    "    num_gaps = cases_sorted_all['tumor_type'].nunique() - 1\n",
    "    extra_height = num_gaps * 0.4 # Heuristic for sizing\n",
    "\n",
    "    print(\"  - Plotting grouped EPIC data for all samples...\")\n",
    "    fig_epic, ax_epic = plt.subplots(figsize=(12, len(cases_sorted_all) * 0.2 + extra_height))\n",
    "    plot_cnv_heatmap(\n",
    "        ngs_data=pd.DataFrame(),\n",
    "        epic_data=epic_segments_df,\n",
    "        cases_info=cases_sorted_all,\n",
    "        chrom_info=chroms_df,\n",
    "        title='CNV heatmap (EPIC)',\n",
    "        ax=ax_epic,\n",
    "        show_tumor_type_axis=False,\n",
    "        group_by_column='tumor_type'\n",
    "    )\n",
    "    fname_epic = PLOT_OUTPUT_DIR / 'heatmap' / \"cnv_heatmap_all_cases_EPIC_grouped.png\"\n",
    "    plt.savefig(fname_epic, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  - Saved grouped EPIC heatmap: {fname_epic}\")\n",
    "    plt.show()\n",
    "    plt.close(fig_epic)\n",
    "\n",
    "    print(\"  - Plotting grouped NGS data for all samples...\")\n",
    "    fig_ngs, ax_ngs = plt.subplots(figsize=(12, len(cases_sorted_all) * 0.2 + extra_height))\n",
    "    plot_cnv_heatmap(\n",
    "        ngs_data=ngs_segments_df,\n",
    "        epic_data=pd.DataFrame(),\n",
    "        cases_info=cases_sorted_all,\n",
    "        chrom_info=chroms_df,\n",
    "        title='CNV heatmap (NGS)',\n",
    "        ax=ax_ngs,\n",
    "        show_tumor_type_axis=False,\n",
    "        group_by_column='tumor_type'\n",
    "    )\n",
    "    fname_ngs = PLOT_OUTPUT_DIR / 'heatmap' / \"cnv_heatmap_all_cases_NGS_grouped.png\"\n",
    "    plt.savefig(fname_ngs, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  - Saved grouped NGS heatmap: {fname_ngs}\")\n",
    "    plt.show()\n",
    "    plt.close(fig_ngs)\n",
    "\n",
    "print(\"\\n--- Batch heatmap generation complete ---\")"
   ],
   "id": "3cf35ac9018edbce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arm_correlations_df['pearson_r'].mean().round(3)",
   "id": "4a2d60e0fa3030ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arm_correlations_df['p_value'].mean().round(6)",
   "id": "9a61b256557caf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Stratified Correlation Analysis by DNA Quality (DIN)\n",
    "# This analysis separates the cohort into two groups based on the DIN value\n",
    "# and calculates the per-arm correlations for each group.\n",
    "\n",
    "print(\"=== Starting Stratified Correlation Analysis by DIN ===\")\n",
    "\n",
    "if 'DIN' not in cases_df.columns:\n",
    "    print(\"Warning: 'DIN' column not found in cases_df. Skipping stratified analysis.\")\n",
    "else:\n",
    "    # Stratify cases into two groups\n",
    "    low_din_cases = cases_df[cases_df['DIN'] <= 6]['case_n_number'].tolist()\n",
    "    high_din_cases = cases_df[cases_df['DIN'] > 6]['case_n_number'].tolist()\n",
    "\n",
    "    print(f\"\\nLow DIN (<= 6) group size: {len(low_din_cases)} cases\")\n",
    "    print(f\"High DIN (> 6) group size: {len(high_din_cases)} cases\")\n",
    "\n",
    "    def run_and_print_stratified_correlation(ngs_agg, epic_agg, cases_list, group_title):\n",
    "        print(f\"\\n--- {group_title} ---\")\n",
    "        if not cases_list or ngs_agg.empty or epic_agg.empty:\n",
    "            print(\"Not enough data to proceed.\")\n",
    "            return\n",
    "\n",
    "        # Filter the main aggregated dataframes by the stratified case lists\n",
    "        ngs_subset = ngs_agg[ngs_agg['case_n_number'].isin(cases_list)]\n",
    "        epic_subset = epic_agg[epic_agg['case_n_number'].isin(cases_list)]\n",
    "\n",
    "        if ngs_subset.empty or epic_subset.empty:\n",
    "            print(\"Subsets for NGS or EPIC are empty for this group.\")\n",
    "            return\n",
    "\n",
    "        # Calculate correlations for the subset\n",
    "        arm_corr_stats = calculate_arm_correlations(ngs_subset, epic_subset)\n",
    "\n",
    "        if arm_corr_stats.empty:\n",
    "            print(\"No overlapping arms found to calculate correlation.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Mean r: {arm_corr_stats['pearson_r'].mean():.3f}\")\n",
    "        print(f\"Mean p-value: {arm_corr_stats['p_value'].mean():.5f}\")\n",
    "        print(\"Per-arm correlation statistics:\")\n",
    "        print(arm_corr_stats)\n",
    "\n",
    "    # Run the analysis for both groups\n",
    "    run_and_print_stratified_correlation(ngs_arm_aggregated_all, epic_df_aggregated_all, low_din_cases, 'Low DIN Group (DIN <= 6)')\n",
    "    run_and_print_stratified_correlation(ngs_arm_aggregated_all, epic_df_aggregated_all, high_din_cases, 'High DIN Group (DIN > 6)')"
   ],
   "id": "a77713aaa92de46f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
