{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from intervaltree import IntervalTree\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "\n",
    "PLOT_Y_LIM = 10\n",
    "GENE_ANNOTATION_PADDING = 0\n",
    "GENE_MERGE_DISTANCE = 2_000_000\n",
    "\n",
    "SEX_PREDICTION_FEMALE_Q = 0.25\n",
    "SEX_PREDICTION_MALE_Q = 0.75\n",
    "\n",
    "SEX_PREDICTION_FEMALE_CONFIDENT_THRESHOLD = -10.0\n",
    "SEX_PREDICTION_MALE_CONFIDENT_THRESHOLD = 0.0\n",
    "\n",
    "SEX_PREDICTION_AMBIGUOUS_THRESHOLD = -3.0\n",
    "\n",
    "ARM_COLORS = {'p': 'tab:blue', 'q': 'tab:orange', 'spanning': 'tab:green', None: 'grey'}\n",
    "\n",
    "BASE_DATA_DIR = Path('data')\n",
    "PLOT_OUTPUT_DIR = Path('graphics')\n",
    "PLOT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CASES_FILE_PATH = BASE_DATA_DIR / 'cases.csv'\n",
    "CYTOBAND_FILE_PATH = BASE_DATA_DIR / 'cytoBand.txt'\n",
    "RELEVANT_GENES_FILE_PATH = BASE_DATA_DIR / 'relevant_genes.csv'\n",
    "\n",
    "# For cases_df processing\n",
    "CASES_COLUMNS_INDICES = [1, 2, 3, 5, 13, 14]\n",
    "CASES_COLUMN_NAMES = ['case_n_number', 'age', 'sex', 'diagnosis', 'sentrix_id', 'barcode']\n",
    "\n",
    "# For cytoband_df processing\n",
    "CYTOBAND_COLUMN_NAMES = ['chromosome', 'start', 'end', 'band', 'giemsa']\n",
    "\n",
    "# For relevant_genes_df processing\n",
    "RELEVANT_GENES_COLUMN_NAMES = ['gene', 'chromosome', 'start', 'end']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _sanitize_chromosome_column(df, chromosome_col='chromosome'):\n",
    "    \"\"\"\n",
    "    Converts a chromosome column to numeric Int64Dtype, replacing 'chr' prefix\n",
    "    and mapping sex chromosomes to numeric equivalents (X->23, Y->24).\n",
    "    Rows with unparsable chromosome values are dropped.\n",
    "    \"\"\"\n",
    "    if chromosome_col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    # Standardize to string, lowercase, and remove 'chr'\n",
    "    s = df[chromosome_col].astype(str).str.lower().str.replace('chr', '', regex=False)\n",
    "\n",
    "    # Map sex and mitochondrial chromosomes to numeric representations\n",
    "    s = s.replace({'x': '23', 'y': '24', 'm': '25', 'mt': '25'})\n",
    "\n",
    "    # Coerce to numeric, dropping any rows that can't be converted\n",
    "    df[chromosome_col] = pd.to_numeric(s, errors='coerce')\n",
    "    df = df.dropna(subset=[chromosome_col])\n",
    "\n",
    "    # Convert to an integer type that supports NaNs\n",
    "    df[chromosome_col] = df[chromosome_col].astype(pd.Int64Dtype())\n",
    "    return df"
   ],
   "id": "1f9b6aff101458ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_cases(file_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the cases data from a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Cases file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.iloc[:, CASES_COLUMNS_INDICES]\n",
    "    df.columns = CASES_COLUMN_NAMES\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df"
   ],
   "id": "3f1dee0dd1ec9b04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_cytoband(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', names=CYTOBAND_COLUMN_NAMES)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Cytoband file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    return _sanitize_chromosome_column(df, 'chromosome')\n",
    "\n",
    "\n",
    "def calculate_chromosome_features(cytoband_df):\n",
    "    if cytoband_df.empty:\n",
    "        return pd.DataFrame(columns=['chromosome', 'length', 'chromosome_absolute_start']), {}\n",
    "    chromosomes_df = (\n",
    "        cytoband_df\n",
    "        .groupby('chromosome')\n",
    "        .agg(length=('end', 'max'))\n",
    "        .reset_index()\n",
    "        .sort_values('chromosome')\n",
    "    )\n",
    "    chromosomes_df['chromosome_absolute_start'] = chromosomes_df['length'].cumsum() - chromosomes_df['length']\n",
    "    chromosome_start_map = chromosomes_df.set_index('chromosome')['chromosome_absolute_start'].to_dict()\n",
    "    return chromosomes_df, chromosome_start_map\n",
    "\n",
    "\n",
    "def create_arm_mapping_df(cytoband_df, chromosome_start_map):\n",
    "    if cytoband_df.empty or not chromosome_start_map:\n",
    "        return pd.DataFrame(columns=['chromosome', 'arm', 'arm_start', 'arm_end', 'arm_abs_start', 'arm_abs_end'])\n",
    "    chromosome_starts_series = pd.Series(chromosome_start_map, name='chr_abs_start').reset_index().rename(\n",
    "        columns={'index': 'chromosome_num'})\n",
    "    arm_df = (\n",
    "        cytoband_df\n",
    "        .assign(arm=lambda x: x['band'].astype(str).str[0].str.lower())\n",
    "        .groupby(['chromosome', 'arm'])\n",
    "        .agg(arm_start=('start', 'min'), arm_end=('end', 'max'))\n",
    "        .reset_index()\n",
    "        .merge(chromosome_starts_series, left_on='chromosome', right_on='chromosome_num')\n",
    "        .assign(\n",
    "            arm_abs_start=lambda x: x['chr_abs_start'] + x['arm_start'],\n",
    "            arm_abs_end=lambda x: x['chr_abs_start'] + x['arm_end']\n",
    "        )\n",
    "        [['chromosome', 'arm', 'arm_start', 'arm_end', 'arm_abs_start', 'arm_abs_end']]\n",
    "    )\n",
    "    return arm_df\n",
    "\n",
    "\n",
    "def create_arm_lookup_table(arm_mapping_df):\n",
    "    \"\"\"Pivots arm_mapping_df for easy lookup of p/q arm start/end.\"\"\"\n",
    "    if arm_mapping_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    arm_lookup = arm_mapping_df.pivot(index='chromosome', columns='arm',\n",
    "                                      values=['arm_start', 'arm_end'])\n",
    "    if not arm_lookup.empty:  # Ensure columns exist before renaming\n",
    "        # Dynamically create new column names based on available arms (p, q or both)\n",
    "        new_cols = []\n",
    "        for val_type in ['arm_start', 'arm_end']:\n",
    "            for arm_type in ['p', 'q']:  # Assuming p and q are the primary arms\n",
    "                if (val_type, arm_type) in arm_lookup.columns:\n",
    "                    new_cols.append(f'{arm_type}_{val_type.split(\"_\")[1]}')  # e.g. p_start, q_end\n",
    "                else:  # Handle cases where an arm might be missing for a chromosome (though rare for p/q)\n",
    "                    new_cols.append(None)  # Placeholder for missing data\n",
    "\n",
    "        # Filter out None placeholders if any arm was completely missing\n",
    "        # And ensure the resulting columns match expected structure (p_start, p_end, q_start, q_end)\n",
    "        # This part needs to be robust if arm_mapping_df is sparse for some chromosomes\n",
    "        # For simplicity, assuming 'p' and 'q' arms are typically present for autosomes.\n",
    "        # If a chromosome only has 'p' or 'q', pivot will result in NaNs for the other.\n",
    "        cols_to_rename = {}\n",
    "        if ('arm_start', 'p') in arm_lookup.columns: cols_to_rename[('arm_start', 'p')] = 'p_start'\n",
    "        if ('arm_end', 'p') in arm_lookup.columns: cols_to_rename[('arm_end', 'p')] = 'p_end'\n",
    "        if ('arm_start', 'q') in arm_lookup.columns: cols_to_rename[('arm_start', 'q')] = 'q_start'\n",
    "        if ('arm_end', 'q') in arm_lookup.columns: cols_to_rename[('arm_end', 'q')] = 'q_end'\n",
    "\n",
    "        arm_lookup.columns = ['_'.join(col).strip() for col in arm_lookup.columns.values]  # Flatten MultiIndex\n",
    "        arm_lookup = arm_lookup.rename(columns={\n",
    "            'arm_start_p': 'p_start', 'arm_end_p': 'p_end',\n",
    "            'arm_start_q': 'q_start', 'arm_end_q': 'q_end'\n",
    "        })\n",
    "        # Ensure all four columns exist, adding them with NaNs if not created by pivot\n",
    "        for col in ['p_start', 'p_end', 'q_start', 'q_end']:\n",
    "            if col not in arm_lookup.columns:\n",
    "                arm_lookup[col] = np.nan\n",
    "    return arm_lookup"
   ],
   "id": "8144f3bc33a9489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_relevant_genes(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=';', names=RELEVANT_GENES_COLUMN_NAMES)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Relevant genes file not found at {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    # _sanitize_chromosome_column ensures 'chromosome' is int\n",
    "    return _sanitize_chromosome_column(df, 'chromosome')\n",
    "\n",
    "\n",
    "def build_gene_interval_trees(relevant_genes_df):\n",
    "    \"\"\"Builds a dictionary of IntervalTrees for gene lookups, per chromosome.\"\"\"\n",
    "    if relevant_genes_df.empty: return {}\n",
    "    trees = {}\n",
    "    for _, row in relevant_genes_df.iterrows():\n",
    "        chrom = row.chromosome\n",
    "        if chrom not in trees:\n",
    "            trees[chrom] = IntervalTree()\n",
    "\n",
    "        start = int(row.start)\n",
    "        end = int(row.end) + 1\n",
    "\n",
    "        # Store the original start/end in the data payload for reference.\n",
    "        trees[chrom].addi(start, end, {'gene': row.gene, 'start': int(row.start), 'end': int(row.end)})\n",
    "\n",
    "    return trees\n",
    "\n",
    "\n",
    "def annotate_segments_with_genes(df, gene_interval_trees, genes_df):\n",
    "    \"\"\"\n",
    "    Annotates DataFrame segments with overlapping genes from the relevant_genes list,\n",
    "    applying logic on a per-case basis to correctly handle pre-annotated genes.\n",
    "    \"\"\"\n",
    "    if df.empty or not gene_interval_trees:\n",
    "        if 'gene' not in df.columns:\n",
    "            df['gene'] = pd.NA\n",
    "        return df\n",
    "\n",
    "    # --- Pre-computation ---\n",
    "    all_relevant_genes = set(genes_df['gene'])\n",
    "    case_id_col = 'case_n_number'\n",
    "\n",
    "    # Ensure a 'gene' column exists and sanitize it globally first.\n",
    "    # This is efficient and removes junk like 'Antitarget' from all rows.\n",
    "    if 'gene' not in df.columns:\n",
    "        df['gene'] = pd.NA\n",
    "    df['gene'] = df['gene'].where(df['gene'].isin(all_relevant_genes), pd.NA)\n",
    "\n",
    "    # Ensure chromosome column is numeric for tree lookups.\n",
    "    df['chromosome'] = pd.to_numeric(df['chromosome'], errors='coerce')\n",
    "\n",
    "    # --- Per-Case Annotation Logic ---\n",
    "    processed_cases = []\n",
    "    for case_id, case_df in df.groupby(case_id_col):\n",
    "        case_df = case_df.copy()\n",
    "\n",
    "        # Identify genes already validly annotated for this case\n",
    "        genes_on_panel_for_this_case = set(case_df['gene'].dropna())\n",
    "\n",
    "        # Identify rows that still need annotation within THIS case.\n",
    "        rows_to_annotate_mask = case_df['gene'].isna()\n",
    "        rows_to_annotate_indices = case_df.index[rows_to_annotate_mask]\n",
    "\n",
    "        # Iterate through and annotate only the necessary rows for this case.\n",
    "        for index in rows_to_annotate_indices:\n",
    "            row = case_df.loc[index]\n",
    "\n",
    "            if pd.isna(row.chromosome):\n",
    "                continue\n",
    "\n",
    "            tree = gene_interval_trees.get(int(row.chromosome))\n",
    "            if not tree:\n",
    "                continue\n",
    "\n",
    "            overlaps = tree.overlap(row.start, row.end)\n",
    "            if overlaps:\n",
    "                # Filter out genes that are already on this specific case's panel.\n",
    "                additional_gene_overlaps = {\n",
    "                    iv for iv in overlaps if iv.data['gene'] not in genes_on_panel_for_this_case\n",
    "                }\n",
    "\n",
    "                if additional_gene_overlaps:\n",
    "                    first_overlap = sorted(additional_gene_overlaps, key=lambda i: (i.begin, i.data['gene']))[0]\n",
    "                    case_df.at[index, 'gene'] = first_overlap.data['gene']\n",
    "\n",
    "        processed_cases.append(case_df)\n",
    "\n",
    "    # Recombine all the processed cases into a single DataFrame.\n",
    "    if not processed_cases:\n",
    "        return pd.DataFrame(columns=df.columns)  # Return empty DF if no cases were processed\n",
    "\n",
    "    return pd.concat(processed_cases, ignore_index=True)\n",
    "\n",
    "\n",
    "def aggregate_data_by_gene(annotated_df, merge_distance=GENE_MERGE_DISTANCE):\n",
    "    \"\"\"Aggregates log2 data to gene level and merges nearby genes, on a per-case basis.\"\"\"\n",
    "    if (annotated_df.empty or\n",
    "            'gene' not in annotated_df.columns or\n",
    "            'absolute_start' not in annotated_df.columns or\n",
    "            'log2' not in annotated_df.columns):\n",
    "        print(\"Warning: Cannot aggregate by gene due to missing columns.\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    case_id_col = 'case_n_number'\n",
    "    if case_id_col not in annotated_df.columns:\n",
    "        print(f\"Warning: Expected column '{case_id_col}' not found.\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ngs_with_gene = annotated_df[annotated_df['gene'].notna() & annotated_df['log2'].notna()].copy()\n",
    "    if ngs_with_gene.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_cases_final_reps = []\n",
    "\n",
    "    for case_id, case_df in ngs_with_gene.groupby(case_id_col):\n",
    "\n",
    "        # Aggregate to gene-level for this single case\n",
    "        gene_reps_case = case_df.groupby('gene').agg(\n",
    "            absolute_position=('absolute_start', 'median'),\n",
    "            log2=('log2', 'median')\n",
    "        ).reset_index()\n",
    "\n",
    "        if gene_reps_case.empty:\n",
    "            continue\n",
    "\n",
    "        # Sort genes by position for this single case\n",
    "        gene_reps_case = gene_reps_case.sort_values('absolute_position').reset_index(drop=True)\n",
    "\n",
    "        # Apply only to this case's genes\n",
    "        if merge_distance <= 0:\n",
    "            final_reps_data_case = gene_reps_case.to_dict('records')\n",
    "        else:\n",
    "            groups = []\n",
    "            current_group = []\n",
    "            for _, row in gene_reps_case.iterrows():\n",
    "                if not current_group:\n",
    "                    current_group.append(row)\n",
    "                    continue\n",
    "\n",
    "                last_row_in_group = current_group[-1]\n",
    "                if (row.absolute_position - last_row_in_group.absolute_position) > merge_distance:\n",
    "                    groups.append(current_group)\n",
    "                    current_group = [row]\n",
    "                else:\n",
    "                    current_group.append(row)\n",
    "\n",
    "            if current_group:\n",
    "                groups.append(current_group)\n",
    "\n",
    "            # Re-aggregate the grouped genes for this single case\n",
    "            final_reps_data_case = []\n",
    "            for group in groups:\n",
    "                group_df = pd.DataFrame(group)\n",
    "                if len(group_df) == 1:\n",
    "                    merged_row = group_df.iloc[0].to_dict()\n",
    "                else:\n",
    "                    unique_genes = sorted(list(set(group_df['gene'])))\n",
    "                    merged_name = _merge_gene_names(unique_genes)\n",
    "                    merged_row = {\n",
    "                        'gene': merged_name,\n",
    "                        'absolute_position': group_df['absolute_position'].median(),\n",
    "                        'log2': group_df.loc[group_df['log2'].abs().idxmax()]['log2']\n",
    "                    }\n",
    "                merged_row[case_id_col] = case_id  # Add the case identifier back\n",
    "                final_reps_data_case.append(merged_row)\n",
    "\n",
    "        all_cases_final_reps.extend(final_reps_data_case)\n",
    "\n",
    "    if not all_cases_final_reps:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Create the final DataFrame from all processed cases\n",
    "    merged_gene_reps = pd.DataFrame(all_cases_final_reps)\n",
    "    merged_gene_reps['log2'] = merged_gene_reps['log2'].clip(lower=-PLOT_Y_LIM, upper=PLOT_Y_LIM)\n",
    "\n",
    "    return merged_gene_reps\n",
    "\n",
    "\n",
    "def _merge_gene_names(gene_list):\n",
    "    \"\"\"\n",
    "    Merges a list of gene names intelligently.\n",
    "    e.g., ['CDKN2A', 'CDKN2B'] becomes 'CDKN2A/B'.\n",
    "    \"\"\"\n",
    "    if len(gene_list) <= 1:\n",
    "        return '/'.join(gene_list)\n",
    "\n",
    "    prefix = path.commonprefix(gene_list)\n",
    "\n",
    "    # If the prefix is trivial, don't shorten, just join\n",
    "    if len(prefix) < 3:\n",
    "        return '/'.join(gene_list)\n",
    "\n",
    "    # Keep the first gene name whole, append only suffixes of the rest\n",
    "    suffixes = [gene[len(prefix):] for gene in gene_list[1:]]\n",
    "    return '/'.join([gene_list[0]] + suffixes)"
   ],
   "id": "6c57f1453bc63e98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_seg_cnr_file(is_seg, item_id, case_id, base_dir):  # Combined loader\n",
    "    sub_path = 'epic/seg' if is_seg else 'ngs/cnr'\n",
    "    file_suffix = '_CNV.seg' if is_seg else '.cnr'  # CNR glob pattern handled inside\n",
    "\n",
    "    if is_seg:\n",
    "        path = base_dir / sub_path / f'{item_id}{file_suffix}'\n",
    "        if not path.exists(): return None\n",
    "    else:  # CNR file, use glob\n",
    "        cnr_dir = base_dir / sub_path\n",
    "        item_id_str = str(item_id) if pd.notna(item_id) else \"\"\n",
    "        if not item_id_str: return None\n",
    "        matches = list(cnr_dir.glob(f'*{item_id_str}*{file_suffix}'))\n",
    "        if not matches: return None\n",
    "        path = matches[0]\n",
    "\n",
    "    try:\n",
    "        names = ['fsid', 'chromosome', 'start', 'end', 'log2'] if is_seg else None  # Auto-detect for CNR\n",
    "        df = pd.read_csv(path, sep='\\t', skiprows=1 if is_seg else 0,\n",
    "                         usecols=[0, 1, 2, 3, 7] if is_seg else None, names=names)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    df['case_n_number'] = case_id\n",
    "    if is_seg:\n",
    "        df['sentrix_id'] = item_id\n",
    "        df = df.drop(columns=['fsid'])\n",
    "    else:  # CNR specific\n",
    "        df['barcode'] = item_id\n",
    "        is_antitarget = (df['gene'] == 'Antitarget')\n",
    "        df.loc[is_antitarget, 'gene'] = pd.NA\n",
    "        if 'log2' in df.columns: df = df[df['log2'].abs() < 6].copy()\n",
    "\n",
    "    return _sanitize_chromosome_column(df)\n",
    "\n",
    "\n",
    "def _normalize_log2(dfs, col='log2'):\n",
    "    if not dfs: return []\n",
    "    vals = pd.concat([d[col] for d in dfs if col in d.columns and not d.empty], ignore_index=True)\n",
    "    if vals.empty: return [d.copy() for d in dfs]\n",
    "    m, s = vals.mean(), vals.std()\n",
    "    s = 1.0 if (pd.isna(s) or s == 0) else s\n",
    "    return [(d.assign(**{col: (d[col] - m) / s}) if col in d.columns and not d.empty else d.copy()) for d in dfs]\n",
    "\n",
    "\n",
    "def load_combine_genomic(cases, bdir, is_seg_loader, id_col, cid_col='case_n_number', l2_col='log2'):\n",
    "    raw = []\n",
    "    for _, r in cases.iterrows():\n",
    "        iid, csid = r[id_col], r[cid_col]\n",
    "        if pd.isna(iid) or pd.isna(csid) or str(iid) == '0': continue\n",
    "        df = load_seg_cnr_file(is_seg_loader, str(iid), str(csid), bdir)  # Pass boolean flag\n",
    "        if df is not None and not df.empty: raw.append(df)\n",
    "    if not raw: return pd.DataFrame()\n",
    "    return pd.concat(_normalize_log2(raw, l2_col), ignore_index=True) if raw else pd.DataFrame()\n",
    "\n",
    "\n",
    "def add_segment_arm_classification(df, arm_lookup_table):\n",
    "    if df.empty or arm_lookup_table.empty:\n",
    "        df['segment_arm'] = None\n",
    "        return df\n",
    "    df['chromosome'] = df['chromosome'].astype(int)\n",
    "    dfa = df.merge(arm_lookup_table, on='chromosome', how='left')\n",
    "    for pos in ['start', 'end']:\n",
    "        ps, pe, qs, qe = (dfa[c].fillna(float('-inf') if 'start' in c else float('inf')) for c in\n",
    "                          ['p_start', 'p_end', 'q_start', 'q_end'])\n",
    "        dfa[f'{pos}_arm'] = np.select([(dfa[pos] >= ps) & (dfa[pos] < pe), (dfa[pos] >= qs) & (dfa[pos] < qe)],\n",
    "                                      ['p', 'q'], default=None)\n",
    "    dfa['segment_arm'] = np.where(dfa['start_arm'] == dfa['end_arm'], dfa['start_arm'], 'spanning')\n",
    "    dfa.loc[(dfa['start_arm'].notna() & dfa['end_arm'].notna() & (\n",
    "            dfa['start_arm'] != dfa['end_arm'])), 'segment_arm'] = 'spanning'\n",
    "    dfa.loc[\n",
    "        (dfa['start_arm'].isna() | dfa['end_arm'].isna()) & (dfa['start_arm'] != dfa['end_arm']), 'segment_arm'] = None\n",
    "    return dfa.drop(\n",
    "        columns=[c for c in ['p_start', 'p_end', 'q_start', 'q_end', 'start_arm', 'end_arm'] if c in dfa.columns])\n",
    "\n",
    "\n"
   ],
   "id": "1d5dc7ce39bac0ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_arm_log2_from_seg(classified_seg_df, arm_map_df, id_col_name='sentrix_id'):\n",
    "    \"\"\"\n",
    "    Aggregates log2 from SEG data to arm level using segment clipping.\n",
    "    Weights log2 by clipped segment coverage within the arm.\n",
    "    \"\"\"\n",
    "    if classified_seg_df.empty or arm_map_df.empty: return pd.DataFrame()\n",
    "    if 'segment_arm' not in classified_seg_df.columns: return pd.DataFrame()  # Need classification\n",
    "\n",
    "    df = classified_seg_df.copy()\n",
    "    df['chromosome'] = df['chromosome'].astype(int)\n",
    "    arm_map_df['chromosome'] = arm_map_df['chromosome'].astype(int)\n",
    "\n",
    "    results = []\n",
    "    for (case, chrom), group in df.groupby(['case_n_number', 'chromosome']):\n",
    "        chrom_arm_info = arm_map_df[arm_map_df['chromosome'] == chrom]\n",
    "        for _, arm_row in chrom_arm_info.iterrows():\n",
    "            arm, arm_start, arm_end, arm_abs_start = arm_row['arm'], arm_row['arm_start'], arm_row['arm_end'], arm_row[\n",
    "                'arm_abs_start']\n",
    "\n",
    "            # Select relevant segments (classified to this arm OR spanning) & overlapping the arm physically\n",
    "            mask = (((group['segment_arm'] == arm) | (group['segment_arm'] == 'spanning')) &\n",
    "                    (group['end'] > arm_start) & (group['start'] < arm_end))\n",
    "            relevant_segments = group[mask].copy()\n",
    "\n",
    "            item_id_val = None\n",
    "            if not relevant_segments.empty:\n",
    "                # Clip segments to arm boundaries\n",
    "                relevant_segments['s_clip'] = relevant_segments['start'].clip(lower=arm_start)\n",
    "                relevant_segments['e_clip'] = relevant_segments['end'].clip(upper=arm_end)\n",
    "                relevant_segments['clip_cov'] = relevant_segments['e_clip'] - relevant_segments['s_clip']\n",
    "                valid_clipped = relevant_segments[relevant_segments['clip_cov'] > 0]\n",
    "\n",
    "                if not valid_clipped.empty:\n",
    "                    total_clip_cov = valid_clipped['clip_cov'].sum()\n",
    "                    log2_agg = (valid_clipped['log2'] * valid_clipped[\n",
    "                        'clip_cov']).sum() / total_clip_cov if total_clip_cov > 0 else np.nan\n",
    "                    agg_start, agg_end = valid_clipped['s_clip'].min(), valid_clipped['e_clip'].max()\n",
    "                    if id_col_name in valid_clipped.columns: item_id_val = valid_clipped[id_col_name].iloc[0]\n",
    "                else:\n",
    "                    log2_agg, agg_start, agg_end = np.nan, arm_start, arm_end\n",
    "            else:\n",
    "                log2_agg, agg_start, agg_end = np.nan, arm_start, arm_end\n",
    "\n",
    "            abs_start = arm_abs_start + (agg_start - arm_start)\n",
    "            abs_end = arm_abs_start + (agg_end - arm_start)\n",
    "            entry = {'case_n_number': case, 'chromosome': chrom, 'segment_arm': arm, 'log2': log2_agg,\n",
    "                     'start': agg_start, 'end': agg_end, 'absolute_start': abs_start, 'absolute_end': abs_end}\n",
    "            if item_id_val is not None: entry[id_col_name] = item_id_val\n",
    "            results.append(entry)\n",
    "\n",
    "    return pd.DataFrame(results).dropna(subset=['log2'])\n",
    "\n",
    "\n",
    "# --- Functions specific to NGS/CNR aggregation ---\n",
    "\n",
    "def prep_ngs_agg(df, chrom_start_map):\n",
    "    \"\"\"Prepares NGS data for arm aggregation: calculates absolute midpoints and length.\"\"\"\n",
    "    if df.empty or not chrom_start_map: return df\n",
    "    df['chromosome'] = df['chromosome'].astype(int)  # Ensure int for mapping\n",
    "    # Calculate absolute start based on bin midpoint\n",
    "    df['absolute_start'] = df['chromosome'].map(chrom_start_map) + ((df['start'] + df['end']) // 2)\n",
    "    df['length'] = df['end'] - df['start']  # Length of the bin\n",
    "    return df\n",
    "\n",
    "\n",
    "def agg_ngs_points_to_arms(classified_ngs_df, chrom_features_df):\n",
    "    \"\"\"Aggregates NGS points/bins to arms based on classification ('p','q','spanning').\"\"\"\n",
    "    if classified_ngs_df.empty or 'segment_arm' not in classified_ngs_df.columns or chrom_features_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Work with valid points having classification and positive length (for weighting)\n",
    "    ngs_valid = classified_ngs_df[classified_ngs_df['segment_arm'].notna()].copy()\n",
    "    if 'length' not in ngs_valid.columns:  # Ensure length exists\n",
    "        ngs_valid['length'] = ngs_valid['end'] - ngs_valid['start']\n",
    "    ngs_valid = ngs_valid[ngs_valid['length'] > 0]\n",
    "    if ngs_valid.empty: return pd.DataFrame()\n",
    "\n",
    "    ngs_valid['chromosome'] = ngs_valid['chromosome'].astype(int)\n",
    "    chrom_features_df['chromosome'] = chrom_features_df['chromosome'].astype(int)\n",
    "\n",
    "    # Aggregate using weighted average, weighted by bin length\n",
    "    arm_agg = (\n",
    "        ngs_valid.groupby(['case_n_number', 'chromosome', 'segment_arm'])\n",
    "        .agg(\n",
    "            log2=('log2', lambda x: np.average(x, weights=ngs_valid.loc[\n",
    "                x.index, 'length']) if not x.empty and x.notna().any() else np.nan),\n",
    "            arm_start=('start', 'min'),\n",
    "            arm_end=('end', 'max'),\n",
    "            # Optional: count number of bins per arm aggregate\n",
    "            # num_bins = ('start', 'size')\n",
    "        ).reset_index()\n",
    "    )\n",
    "\n",
    "    # Add absolute start/end for the aggregated arm segment\n",
    "    arm_agg = arm_agg.merge(chrom_features_df[['chromosome', 'chromosome_absolute_start']], on='chromosome', how='left')\n",
    "    arm_agg['arm_absolute_start'] = arm_agg['chromosome_absolute_start'] + arm_agg['arm_start']\n",
    "    arm_agg['arm_absolute_end'] = arm_agg['chromosome_absolute_start'] + arm_agg['arm_end']\n",
    "\n",
    "    return arm_agg.drop(columns=['chromosome_absolute_start'], errors='ignore').dropna(subset=['log2'])"
   ],
   "id": "782848c86b430081",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_and_add_sex(ngs_df, cases_df, case_id_col='case_n_number'):\n",
    "    \"\"\"\n",
    "    Predicts sex using an asymmetric dual-quantile fitness model and adds the\n",
    "    prediction and a confidence score to the cases dataframe.\n",
    "    \"\"\"\n",
    "    if ngs_df.empty or cases_df.empty:\n",
    "        print(\"Warning: Cannot predict sex, input dataframe is empty.\", file=sys.stderr)\n",
    "        cases_df['predicted_sex'] = 'unknown'\n",
    "        cases_df['sex_confidence'] = 0.0\n",
    "        return cases_df\n",
    "\n",
    "    predictions = {}\n",
    "    confidences = {}\n",
    "\n",
    "    print(\"\\n--- Predicting sex for all cases using dual-quantile model ---\")\n",
    "    for case_id, group in ngs_df.groupby(case_id_col):\n",
    "        # Use 24 as the numeric representation for chromosome 'Y'\n",
    "        y_chrom_bins = group[group['chromosome'] == 24]\n",
    "\n",
    "        if y_chrom_bins.empty:\n",
    "            predictions[case_id] = 'unknown'\n",
    "            confidences[case_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        q_female = y_chrom_bins['log2'].quantile(SEX_PREDICTION_FEMALE_Q)\n",
    "        q_male = y_chrom_bins['log2'].quantile(SEX_PREDICTION_MALE_Q)\n",
    "\n",
    "        if pd.isna(q_female) or pd.isna(q_male):\n",
    "            predictions[case_id] = 'unknown'\n",
    "            confidences[case_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        female_range = SEX_PREDICTION_AMBIGUOUS_THRESHOLD - SEX_PREDICTION_FEMALE_CONFIDENT_THRESHOLD\n",
    "        male_range = SEX_PREDICTION_MALE_CONFIDENT_THRESHOLD - SEX_PREDICTION_AMBIGUOUS_THRESHOLD\n",
    "\n",
    "        female_fitness = (SEX_PREDICTION_AMBIGUOUS_THRESHOLD - q_female) / (female_range + 1e-9)\n",
    "        male_fitness = (q_male - SEX_PREDICTION_AMBIGUOUS_THRESHOLD) / (male_range + 1e-9)\n",
    "\n",
    "        female_fitness = np.clip(female_fitness, 0.0, 1.0)\n",
    "        male_fitness = np.clip(male_fitness, 0.0, 1.0)\n",
    "\n",
    "        confidence = abs(female_fitness - male_fitness)\n",
    "\n",
    "        if female_fitness > male_fitness:\n",
    "            prediction = \"female\"\n",
    "        elif male_fitness > female_fitness:\n",
    "            prediction = \"male\"\n",
    "        else:\n",
    "            prediction = \"unknown\"\n",
    "            confidence = 0.0\n",
    "\n",
    "        predictions[case_id] = prediction\n",
    "        confidences[case_id] = confidence\n",
    "\n",
    "    cases_df['predicted_sex'] = cases_df[case_id_col].map(predictions).fillna('unknown')\n",
    "    cases_df['sex_confidence'] = cases_df[case_id_col].map(confidences).fillna(0.0)\n",
    "\n",
    "    print(\"Sex prediction complete. Results added to cases dataframe.\\n\")\n",
    "    return cases_df"
   ],
   "id": "f55eebce83320e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_sex(ngs_df, cases_df, case_id_col='case_n_number'):\n",
    "    \"\"\"\n",
    "    Predicts sex using a self-calibrating, linear scoring system based on the\n",
    "    relative z-scores of the X and Y chromosomes.\n",
    "    \"\"\"\n",
    "    MALE_Z_HIGH_SCORE = -1.5\n",
    "    MALE_Z_LOW_SCORE = 0.0\n",
    "\n",
    "    FEMALE_Z_HIGH_SCORE = -9.0\n",
    "    FEMALE_Z_LOW_SCORE = 0.0\n",
    "\n",
    "    if ngs_df.empty or cases_df.empty:\n",
    "        cases_df['predicted_sex'], cases_df['sex_confidence'] = 'unknown', 0.0\n",
    "        return cases_df\n",
    "\n",
    "    predictions, confidences = {}, {}\n",
    "\n",
    "    for case_id, group in ngs_df.groupby(case_id_col):\n",
    "        # Isolate chromosome data\n",
    "        autosomal_bins = group[(group['chromosome'] >= 1) & (group['chromosome'] <= 22)]\n",
    "        x_bins = group[group['chromosome'] == 23]\n",
    "        y_bins = group[group['chromosome'] == 24]\n",
    "\n",
    "        if autosomal_bins.empty or x_bins.empty or y_bins.empty:\n",
    "            predictions[case_id], confidences[case_id] = 'unknown', 0.0\n",
    "            continue\n",
    "\n",
    "        # Calculate the sample's unique baseline statistics\n",
    "        median_auto = autosomal_bins['log2'].median()\n",
    "        autosomal_std = autosomal_bins['log2'].std()\n",
    "\n",
    "        # Handle cases with no variance\n",
    "        if autosomal_std < 1e-9:\n",
    "            predictions[case_id], confidences[case_id] = 'unknown', 0.0\n",
    "            continue\n",
    "\n",
    "        # Calculate the median log2 for sex chromosomes\n",
    "        median_x = x_bins['log2'].median()\n",
    "        median_y = y_bins['log2'].median()\n",
    "\n",
    "        # Calculate z-scores relative to the sample's own autosomes\n",
    "        z_score_x = (median_x - median_auto) / autosomal_std\n",
    "        z_score_y = (median_y - median_auto) / autosomal_std\n",
    "\n",
    "        # --- Calculate Male Score (0.0 to 1.0) ---\n",
    "        male_range = MALE_Z_LOW_SCORE - MALE_Z_HIGH_SCORE\n",
    "        male_score = (MALE_Z_LOW_SCORE - z_score_x) / male_range\n",
    "        male_score = np.clip(male_score, 0.0, 1.0)\n",
    "\n",
    "        # --- Calculate Female Score (0.0 to 1.0) ---\n",
    "        female_range = FEMALE_Z_LOW_SCORE - FEMALE_Z_HIGH_SCORE\n",
    "        female_score = (FEMALE_Z_LOW_SCORE - z_score_y) / female_range\n",
    "        female_score = np.clip(female_score, 0.0, 1.0)\n",
    "\n",
    "        # --- Decision and Confidence ---\n",
    "        if male_score > female_score:\n",
    "            prediction = \"male\"\n",
    "        else:\n",
    "            prediction = \"female\"\n",
    "\n",
    "        # Confidence is the absolute difference between the scores\n",
    "        confidence = abs(male_score - female_score)\n",
    "\n",
    "        predictions[case_id] = prediction\n",
    "        confidences[case_id] = np.clip(confidence, 0.0, 1.0)\n",
    "\n",
    "    # Map the results back to the main cases dataframe\n",
    "    cases_df['predicted_sex'] = cases_df[case_id_col].map(predictions).fillna('unknown')\n",
    "    cases_df['sex_confidence'] = cases_df[case_id_col].map(confidences).fillna(0.0)\n",
    "\n",
    "    return cases_df"
   ],
   "id": "2cddb4b42de7789c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _plot_ngs_scatter(ax, ngs_df_case):\n",
    "    \"\"\"Plots individual NGS bins. Colors based on log2 value (gain/loss/neutral).\"\"\"\n",
    "    if ngs_df_case.empty or 'log2' not in ngs_df_case.columns or 'absolute_start' not in ngs_df_case.columns:\n",
    "        return\n",
    "\n",
    "    log2_values = pd.to_numeric(ngs_df_case['log2'], errors='coerce').clip(-PLOT_Y_LIM, PLOT_Y_LIM)\n",
    "    abs_pos = ngs_df_case['absolute_start']\n",
    "\n",
    "    # Calculate alpha based on z-score of log2 values\n",
    "    if len(log2_values) > 1:  # zscore needs at least 2 points\n",
    "        # zscore returns a numpy array if input is a Series, re-index to match original\n",
    "        abs_z = np.abs(zscore(log2_values.to_numpy()))\n",
    "        calculated_alphas = np.clip((abs_z / 3) ** 2.25, 0.01, 1.0)\n",
    "        alphas = pd.Series(calculated_alphas, index=log2_values.index)\n",
    "    else:\n",
    "        alphas = pd.Series([0.5], index=log2_values.index)  # Default alpha for a single point\n",
    "\n",
    "    # Define colors\n",
    "    color_gain = 'tab:orange'\n",
    "    color_loss = 'tab:blue'\n",
    "    color_neutral = 'grey'\n",
    "\n",
    "    # Create masks for plotting, excluding NaNs from these categories\n",
    "    mask_gain = (log2_values > 1e-6)  # Use a small epsilon for > 0\n",
    "    mask_loss = (log2_values < -1e-6)  # Use a small epsilon for < 0\n",
    "    mask_neutral = np.isclose(log2_values, 0, atol=1e-6)\n",
    "\n",
    "    # Plot gains\n",
    "    if mask_gain.any():\n",
    "        ax.scatter(abs_pos[mask_gain], log2_values[mask_gain],\n",
    "                   color=color_gain, alpha=alphas[mask_gain], s=2)\n",
    "\n",
    "    # Plot losses\n",
    "    if mask_loss.any():\n",
    "        ax.scatter(abs_pos[mask_loss], log2_values[mask_loss],\n",
    "                   color=color_loss, alpha=alphas[mask_loss], s=2)\n",
    "\n",
    "    # Plot neutral points\n",
    "    if mask_neutral.any():\n",
    "        ax.scatter(abs_pos[mask_neutral], log2_values[mask_neutral],\n",
    "                   color=color_neutral, alpha=alphas[mask_neutral], s=2)\n",
    "\n",
    "\n",
    "def _plot_arm_means(ax, df_aggregated_case, color, linestyle, linewidth, label_text_prefix):\n",
    "    if df_aggregated_case.empty or 'log2' not in df_aggregated_case.columns:\n",
    "        return\n",
    "\n",
    "    start_col = 'arm_absolute_start' if 'arm_absolute_start' in df_aggregated_case.columns else 'absolute_start'\n",
    "    end_col = 'arm_absolute_end' if 'arm_absolute_end' in df_aggregated_case.columns else 'absolute_end'\n",
    "\n",
    "    if not all(c in df_aggregated_case.columns for c in [start_col, end_col, 'log2']):\n",
    "        return\n",
    "\n",
    "    for idx, row in df_aggregated_case.reset_index().iterrows():\n",
    "        if pd.notna(row['log2']) and pd.notna(row[start_col]) and pd.notna(row[end_col]):\n",
    "            ax.plot(\n",
    "                [row[start_col], row[end_col]],\n",
    "                [row['log2'], row['log2']],\n",
    "                color=color,\n",
    "                linestyle=linestyle,\n",
    "                linewidth=linewidth,\n",
    "                label=f'{label_text_prefix}' if idx == 0 else None  # Label only first segment\n",
    "            )\n",
    "\n",
    "\n",
    "def _plot_gene_labels(ax, gene_reps_case):\n",
    "    if gene_reps_case.empty or not all(c in gene_reps_case.columns for c in ['absolute_position', 'log2', 'gene']):\n",
    "        return\n",
    "\n",
    "    valid_gene_reps = gene_reps_case.dropna(subset=['absolute_position', 'log2', 'gene'])\n",
    "    if valid_gene_reps.empty: return\n",
    "\n",
    "    ax.scatter(\n",
    "        valid_gene_reps['absolute_position'],\n",
    "        valid_gene_reps['log2'],\n",
    "        color='black', s=4\n",
    "    )\n",
    "    for _, row in valid_gene_reps.iterrows():\n",
    "        y, name = row['log2'], row['gene']\n",
    "\n",
    "        offset = 0.15 if y > 0 else -0.15\n",
    "        if abs(y) > PLOT_Y_LIM * 0.75:\n",
    "            offset = -1 * offset\n",
    "        va = 'bottom' if offset > 0 else 'top'\n",
    "\n",
    "        ax.text(\n",
    "            row['absolute_position'],\n",
    "            y + offset,\n",
    "            name,\n",
    "            fontsize=8,\n",
    "            ha='center',\n",
    "            va=va,\n",
    "            rotation=90\n",
    "        )\n",
    "\n",
    "\n",
    "def draw_cnv_plot(case_info, df_ngs_case, df_ngs_agg, df_epic_agg, df_gene_reps,\n",
    "                  df_chroms, arm_map_df):\n",
    "    case_n_number = case_info['case_n_number']\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "    # Use the style-specific helper functions\n",
    "    _plot_ngs_scatter(ax, df_ngs_case)\n",
    "    _plot_arm_means(ax, df_ngs_agg, 'purple', '-', 1.5, 'average cnr (ngs sample)')\n",
    "    _plot_arm_means(ax, df_epic_agg, 'purple', '--', 1.0, 'average cnr (epic reference)')\n",
    "    _plot_gene_labels(ax, df_gene_reps)\n",
    "\n",
    "    # Axis lines and ticks\n",
    "    ax.axhline(0, color='grey', linewidth=0.5)\n",
    "\n",
    "    if not df_chroms.empty and all(\n",
    "            c in df_chroms.columns for c in ['chromosome_absolute_start', 'length', 'chromosome']):\n",
    "        chrom_starts = df_chroms['chromosome_absolute_start']\n",
    "        ax.vlines(chrom_starts, -PLOT_Y_LIM, PLOT_Y_LIM,\n",
    "                  color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Draw vertical lines at p/q arm boundaries\n",
    "        if not arm_map_df.empty and 'arm_abs_end' in arm_map_df.columns:\n",
    "            # The end of the 'p' arm is the centromere / p-q boundary\n",
    "            pq_boundaries = arm_map_df.loc[arm_map_df['arm'] == 'p', 'arm_abs_end']\n",
    "            if not pq_boundaries.empty:\n",
    "                ax.vlines(pq_boundaries, -PLOT_Y_LIM, PLOT_Y_LIM,\n",
    "                          color='grey', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        mids = chrom_starts + df_chroms['length'] / 2\n",
    "        ax.set_xticks(mids)\n",
    "\n",
    "        # Create user-friendly labels for ticks, converting 23/24 back to X/Y\n",
    "        xticklabels = df_chroms['chromosome'].astype(str).replace({'23': 'X', '24': 'Y'}).tolist()\n",
    "        ax.set_xticklabels(xticklabels, rotation=90)\n",
    "\n",
    "    xlim_max = df_chroms['chromosome_absolute_start'].iloc[-1] + df_chroms['length'].iloc[-1]\n",
    "\n",
    "    ax.set(\n",
    "        xlim=(0, xlim_max),\n",
    "        ylim=(-PLOT_Y_LIM, PLOT_Y_LIM),\n",
    "        xlabel='genomic position by chromosome',\n",
    "        ylabel='copy number deviation (log2)'\n",
    "    )\n",
    "\n",
    "    plt.suptitle(f'CNV profile of {case_n_number} from NGS sample vs. EPIC reference', fontsize=14)\n",
    "\n",
    "    known_sex = case_info.get('sex', 'N/A')\n",
    "    predicted_sex = case_info.get('predicted_sex', 'N/A')\n",
    "    confidence = case_info.get('sex_confidence', None)\n",
    "\n",
    "    pred_text = predicted_sex\n",
    "    if confidence is not None and predicted_sex != 'unknown':\n",
    "        pred_text += f' {confidence:.0%}'\n",
    "\n",
    "    title_text = (\n",
    "        f\"{known_sex} (prediction: {pred_text}), age {case_info.get('age', 'N/A')}, \"\n",
    "        f\"{case_info.get('diagnosis', 'N/A')}\"\n",
    "    )\n",
    "    plt.title(title_text, fontsize=10, pad=6)\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    (PLOT_OUTPUT_DIR / 'scatter').mkdir(parents=True, exist_ok=True)\n",
    "    fname = PLOT_OUTPUT_DIR / 'scatter' / f\"ngs_scatter_{case_n_number.replace('/', '_')}.png\"\n",
    "    # plt.savefig(fname, dpi=150)\n",
    "    # print(f\"Saved plot: {fname}\") # Commented out to reduce console noise in a loop\n",
    "\n",
    "    plt.show(fig)"
   ],
   "id": "2731c18419e474d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_arm_correlations(ngs_aggregated_df, epic_aggregated_df):\n",
    "    \"\"\"Calculates Pearson correlation between NGS and EPIC log2 values per arm.\"\"\"\n",
    "    if ngs_aggregated_df.empty or epic_aggregated_df.empty:\n",
    "        return pd.DataFrame(columns=['chromosome', 'arm', 'pearson_r', 'p_value', 'n_samples'])\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        ngs_aggregated_df[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        epic_aggregated_df[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        on=['case_n_number', 'chromosome', 'segment_arm'],\n",
    "        suffixes=('_ngs', '_epic'),\n",
    "        how='inner'  # Only cases/arms present in both\n",
    "    )\n",
    "    if merged_df.empty: return pd.DataFrame(columns=['chromosome', 'arm', 'pearson_r', 'p_value', 'n_samples'])\n",
    "\n",
    "    corr_results = []\n",
    "    for (chrom, arm), group in merged_df.groupby(['chromosome', 'segment_arm']):\n",
    "        if len(group) >= 3:  # Pearson r needs at least 2, but more is better\n",
    "            r, p = pearsonr(group['log2_ngs'], group['log2_epic'])\n",
    "        else:\n",
    "            r, p = np.nan, np.nan\n",
    "        corr_results.append({'chromosome': chrom, 'arm': arm, 'pearson_r': r, 'p_value': p, 'n_samples': len(group)})\n",
    "\n",
    "    return pd.DataFrame(corr_results).sort_values(['chromosome', 'arm']).reset_index(drop=True)"
   ],
   "id": "e9935d84fc4a6234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_correlation_scatter(merged_correlation_df, arm_corr_stats_df):\n",
    "    \"\"\"Plots scatter of NGS vs EPIC log2 values, faceted by chromosome, colored by arm, with correlation annotations.\"\"\"\n",
    "    if merged_correlation_df.empty:\n",
    "        print(\"Merged data for correlation plot is empty. Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data=merged_correlation_df, x='log2_ngs', y='log2_epic',\n",
    "        col='chromosome', hue='segment_arm', kind='scatter', palette=ARM_COLORS,\n",
    "        col_wrap=6, height=2, aspect=1, s=20, alpha=0.7,\n",
    "        facet_kws={'sharex': True, 'sharey': True}\n",
    "    )\n",
    "\n",
    "    for ax, chrom_name in zip(g.axes.flat, g.col_names):\n",
    "        if pd.isna(chrom_name): continue  # Skip if chrom_name is NaN (can happen if few chromosomes)\n",
    "        chrom_corrs_on_plot = arm_corr_stats_df[arm_corr_stats_df['chromosome'] == chrom_name]\n",
    "\n",
    "        for arm_label, color in ARM_COLORS.items():\n",
    "            if arm_label is None: continue  # Skip None arm for text annotation\n",
    "            arm_data_for_text = chrom_corrs_on_plot[chrom_corrs_on_plot['arm'] == arm_label]\n",
    "\n",
    "            if not arm_data_for_text.empty and not pd.isna(arm_data_for_text.iloc[0]['pearson_r']):\n",
    "                r_val = arm_data_for_text.iloc[0]['pearson_r']\n",
    "                p_val = arm_data_for_text.iloc[0]['p_value']\n",
    "\n",
    "                text_label = f'r({arm_label})={r_val:.2f}'\n",
    "                x_pos, ha = (0.05, 'left') if arm_label == 'p' else (0.95, 'right')\n",
    "\n",
    "                # Significance highlighting for p-value\n",
    "                bg_color = '#f0f0f0'  # default\n",
    "                if p_val < 0.05: bg_color = '#d4edda'  # green-ish for p < 0.05\n",
    "                if p_val < 0.01: bg_color = '#c3e6cb'  # darker green-ish for p < 0.01\n",
    "\n",
    "                ax.text(x_pos, 0.95, text_label, transform=ax.transAxes, color=color,\n",
    "                        ha=ha, va='top', fontsize=8,\n",
    "                        bbox=dict(facecolor=bg_color, alpha=0.6, edgecolor='none', pad=0.2))\n",
    "\n",
    "    g.set_axis_labels('ngs cn ratio (log2)', 'epic cn ratio (log2)', fontsize=10)\n",
    "    g.fig.subplots_adjust(top=0.92)  # Adjust top for suptitle\n",
    "    g.fig.suptitle('NGS vs EPIC: copy number correlation by chromosome and arm', fontsize=14)\n",
    "\n",
    "    fname = PLOT_OUTPUT_DIR / 'correlation' / \"ngs_epic_arm_correlation.png\"\n",
    "    # plt.savefig(fname, dpi=200)\n",
    "    # print(f\"Saved correlation plot: {fname}\")\n",
    "    plt.show()"
   ],
   "id": "718f7092bf4888e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cases_df = load_and_preprocess_cases(CASES_FILE_PATH)\n",
    "cases_df"
   ],
   "id": "d71ba9e386f8c183",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cytoband_df = load_and_preprocess_cytoband(CYTOBAND_FILE_PATH)\n",
    "cytoband_df"
   ],
   "id": "e12a7a062f4f6e2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genes_df = load_and_preprocess_relevant_genes(RELEVANT_GENES_FILE_PATH)\n",
    "genes_df"
   ],
   "id": "c0c5150170cba5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Base Dir: {BASE_DATA_DIR.resolve()}, Plot Dir: {PLOT_OUTPUT_DIR.resolve()}, Corr. Plot Dir: {PLOT_OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "chroms_df, chrom_map = pd.DataFrame(), {}\n",
    "arm_map_df, arm_lookup_table = pd.DataFrame(), pd.DataFrame()\n",
    "gene_trees = {}\n",
    "\n",
    "if not cytoband_df.empty:\n",
    "    chroms_df, chrom_map = calculate_chromosome_features(cytoband_df)\n",
    "    arm_map_df = create_arm_mapping_df(cytoband_df, chrom_map)\n",
    "    arm_lookup_table = create_arm_lookup_table(arm_map_df)\n",
    "if not genes_df.empty:\n",
    "    gene_trees = build_gene_interval_trees(genes_df)\n",
    "gene_trees"
   ],
   "id": "7ed285c318a30383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process EPIC data\n",
    "epic_df_aggregated_all = pd.DataFrame()\n",
    "if not cases_df.empty and not arm_lookup_table.empty and not arm_map_df.empty:\n",
    "    epic_raw_df = load_combine_genomic(cases_df, BASE_DATA_DIR, True, 'sentrix_id')  # True for SEG\n",
    "    if not epic_raw_df.empty:\n",
    "        epic_classified = add_segment_arm_classification(epic_raw_df.copy(), arm_lookup_table)\n",
    "        epic_df_aggregated_all = calculate_arm_log2_from_seg(epic_classified, arm_map_df, 'sentrix_id')\n",
    "        print(f\"Aggregated EPIC data: {epic_df_aggregated_all.shape}\")\n",
    "\n",
    "epic_df_aggregated_all"
   ],
   "id": "d45cbf9af1626940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process NGS data\n",
    "ngs_df_processed_full = pd.DataFrame()  # For CNV plots (points)\n",
    "ngs_arm_aggregated_all = pd.DataFrame()  # For CNV plots (lines) & correlation\n",
    "ngs_gene_reps_all = pd.DataFrame()  # For CNV plots (gene labels)\n",
    "\n",
    "if not cases_df.empty:\n",
    "    ngs_raw_df = load_combine_genomic(cases_df, BASE_DATA_DIR, False, 'barcode')  # False for CNR\n",
    "    if not ngs_raw_df.empty:\n",
    "        cases_df = predict_sex(ngs_raw_df, cases_df)\n",
    "        ngs_curr = ngs_raw_df.copy()\n",
    "        if chrom_map:\n",
    "            ngs_curr = prep_ngs_agg(ngs_curr, chrom_map)\n",
    "        if not arm_lookup_table.empty:\n",
    "            ngs_curr = add_segment_arm_classification(ngs_curr, arm_lookup_table)\n",
    "        if gene_trees:\n",
    "            ngs_curr = annotate_segments_with_genes(ngs_curr, gene_trees, genes_df)\n",
    "            ngs_gene_reps_all = aggregate_data_by_gene(ngs_curr)\n",
    "        if not chroms_df.empty and 'segment_arm' in ngs_curr.columns:\n",
    "            ngs_arm_aggregated_all = agg_ngs_points_to_arms(ngs_curr, chroms_df)\n",
    "\n",
    "        ngs_df_processed_full = ngs_curr  # This df has points for CNV plot\n",
    "        print(\n",
    "            f\"Processed NGS. Points: {ngs_df_processed_full.shape}, Arm Agg: {ngs_arm_aggregated_all.shape}, Gene Reps: {ngs_gene_reps_all.shape}\")\n",
    "\n",
    "ngs_curr"
   ],
   "id": "399cb51b0c602df6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate CNV plots for each case\n",
    "if not cases_df.empty and not ngs_df_processed_full.empty:\n",
    "    print(f\"\\n--- Generating CNV plots for {len(cases_df)} cases ---\")\n",
    "    for _, case_r in cases_df.iterrows():\n",
    "        cnum = case_r['case_n_number']\n",
    "        ngs_c = ngs_df_processed_full[ngs_df_processed_full['case_n_number'] == cnum].copy()\n",
    "        ngs_agg_c = ngs_arm_aggregated_all[ngs_arm_aggregated_all['case_n_number'] == cnum].copy()\n",
    "        epic_agg_c = epic_df_aggregated_all[epic_df_aggregated_all['case_n_number'] == cnum].copy()\n",
    "        gene_reps_c = ngs_gene_reps_all[ngs_gene_reps_all['case_n_number'] == cnum].copy()\n",
    "        if ngs_c.empty and ngs_agg_c.empty and epic_agg_c.empty and gene_reps_c.empty:\n",
    "            print(f\"Skipping plot for {cnum}: No data.\")\n",
    "            continue\n",
    "        draw_cnv_plot(case_r, ngs_c, ngs_agg_c, epic_agg_c, gene_reps_c, chroms_df, arm_map_df)"
   ],
   "id": "91074dcc86d385c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate and plot correlations\n",
    "if not ngs_arm_aggregated_all.empty and not epic_df_aggregated_all.empty:\n",
    "    print(\"\\n--- Calculating and plotting NGS vs EPIC arm correlations ---\")\n",
    "    arm_correlations_df = calculate_arm_correlations(ngs_arm_aggregated_all, epic_df_aggregated_all)\n",
    "    print(\"Arm correlation:\\n\", arm_correlations_df)\n",
    "\n",
    "    # Need the merged df for plotting points (not just stats)\n",
    "    merged_for_plot = pd.merge(\n",
    "        ngs_arm_aggregated_all[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        epic_df_aggregated_all[['case_n_number', 'chromosome', 'segment_arm', 'log2']],\n",
    "        on=['case_n_number', 'chromosome', 'segment_arm'],\n",
    "        suffixes=('_ngs', '_epic'), how='inner'\n",
    "    )\n",
    "    plot_correlation_scatter(merged_for_plot, arm_correlations_df)\n",
    "else:\n",
    "    print(\"Skipping correlation analysis: Aggregated NGS or EPIC data is missing.\")"
   ],
   "id": "c531e63c61a8b16d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arm_correlations_df['pearson_r'].mean()",
   "id": "a028f85534114d67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arm_correlations_df['pearson_r'].median()",
   "id": "b5dafd265d2cc6b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Integrated Model Testing and Validation Cell ###\n",
    "\n",
    "# This cell tests the \"Linear Z-Score\" model, which uses a linear\n",
    "# scoring system for the male (X-chr) and female (Y-chr) hypotheses.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ensure the required data is available from previous cells\n",
    "if 'ngs_raw_df' not in locals() or 'cases_df' not in locals() or ngs_raw_df.empty or cases_df.empty:\n",
    "    print(\"Error: 'ngs_raw_df' or 'cases_df' is not loaded. Please run the data loading cells first.\", file=sys.stderr)\n",
    "else:\n",
    "    # --- Step 1: Define the Prediction Model to Test ---\n",
    "    def predict_sex_linear_zscore(ngs_df, cases_df, case_id_col='case_n_number'):\n",
    "        \"\"\"\n",
    "        Predicts sex using a linear scoring system based on the relative\n",
    "        z-scores of the X and Y chromosomes.\n",
    "        \"\"\"\n",
    "        # --- Model Parameters (Unitless and statistically meaningful) ---\n",
    "        # For the Male Score (based on z_score_x)\n",
    "        MALE_Z_HIGH_SCORE = -1.5  # The z-score giving a score of 1.0\n",
    "        MALE_Z_LOW_SCORE = 0.0     # The z-score giving a score of 0.0\n",
    "\n",
    "        # For the Female Score (based on z_score_y)\n",
    "        FEMALE_Z_HIGH_SCORE = -9.0 # The z-score giving a score of 1.0\n",
    "        FEMALE_Z_LOW_SCORE = 0.0    # The z-score giving a score of 0.0\n",
    "\n",
    "        predictions, confidences = {}, {}\n",
    "\n",
    "        for case_id, group in ngs_df.groupby(case_id_col):\n",
    "            autosomal_bins = group[(group['chromosome'] >= 1) & (group['chromosome'] <= 22)]\n",
    "            x_bins = group[group['chromosome'] == 23]\n",
    "            y_bins = group[group['chromosome'] == 24]\n",
    "\n",
    "            if autosomal_bins.empty or x_bins.empty or y_bins.empty:\n",
    "                predictions[case_id], confidences[case_id] = 'unknown', 0.0\n",
    "                continue\n",
    "\n",
    "            median_auto = autosomal_bins['log2'].median()\n",
    "            autosomal_std = autosomal_bins['log2'].std()\n",
    "            if autosomal_std < 1e-9:\n",
    "                predictions[case_id], confidences[case_id] = 'unknown', 0.0\n",
    "                continue\n",
    "\n",
    "            median_x = x_bins['log2'].median()\n",
    "            median_y = y_bins['log2'].median()\n",
    "\n",
    "            z_score_x = (median_x - median_auto) / autosomal_std\n",
    "            z_score_y = (median_y - median_auto) / autosomal_std\n",
    "\n",
    "            # --- Calculate Male Score (0.0 to 1.0) ---\n",
    "            male_range = MALE_Z_LOW_SCORE - MALE_Z_HIGH_SCORE\n",
    "            male_score = (MALE_Z_LOW_SCORE - z_score_x) / male_range\n",
    "            male_score = np.clip(male_score, 0.0, 1.0)\n",
    "\n",
    "            # --- Calculate Female Score (0.0 to 1.0) ---\n",
    "            female_range = FEMALE_Z_LOW_SCORE - FEMALE_Z_HIGH_SCORE\n",
    "            female_score = (FEMALE_Z_LOW_SCORE - z_score_y) / female_range\n",
    "            female_score = np.clip(female_score, 0.0, 1.0)\n",
    "\n",
    "            # --- Decision and Confidence ---\n",
    "            if male_score > female_score:\n",
    "                prediction = \"male\"\n",
    "            else:\n",
    "                prediction = \"female\"\n",
    "\n",
    "            confidence = abs(male_score - female_score)\n",
    "\n",
    "            predictions[case_id] = prediction\n",
    "            confidences[case_id] = np.clip(confidence, 0.0, 1.0)\n",
    "\n",
    "        cases_df['predicted_sex'] = cases_df[case_id_col].map(predictions).fillna('unknown')\n",
    "        cases_df['sex_confidence'] = cases_df[case_id_col].map(confidences).fillna(0.0)\n",
    "        return cases_df\n",
    "\n",
    "    # --- Step 2: Run the Prediction ---\n",
    "    print(\"--- Running Sex Prediction using the Linear Z-Score Model ---\")\n",
    "    cases_with_predictions = predict_sex_linear_zscore(ngs_raw_df, cases_df.copy())\n",
    "    print(\"Prediction complete.\")\n",
    "\n",
    "    # --- Step 3: Validate the Results ---\n",
    "    valid_comparison_df = cases_with_predictions[\n",
    "        (cases_with_predictions['sex'].isin(['male', 'female'])) &\n",
    "        (cases_with_predictions['predicted_sex'].isin(['male', 'female']))\n",
    "    ].copy()\n",
    "\n",
    "    if not valid_comparison_df.empty:\n",
    "        print(\"\\n--- Sex Prediction Validation ---\")\n",
    "\n",
    "        incorrect_predictions = valid_comparison_df[\n",
    "            valid_comparison_df['sex'] != valid_comparison_df['predicted_sex']\n",
    "        ]\n",
    "\n",
    "        if not incorrect_predictions.empty:\n",
    "            print(\"\\nIncorrect Predictions Found:\")\n",
    "            print(incorrect_predictions[['case_n_number', 'sex', 'predicted_sex', 'sex_confidence']])\n",
    "        else:\n",
    "            print(\"\\n All predictions were correct!\")\n",
    "\n",
    "        accuracy = accuracy_score(valid_comparison_df['sex'], valid_comparison_df['predicted_sex'])\n",
    "        print(f\"\\nOverall Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "        avg_confidence = valid_comparison_df['sex_confidence'].mean()\n",
    "        print(f\"Average Confidence: {avg_confidence:.2%}\")\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        labels = sorted(list(set(valid_comparison_df['sex'])))\n",
    "        print(classification_report(valid_comparison_df['sex'], valid_comparison_df['predicted_sex'], labels=labels, zero_division=0))\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(valid_comparison_df['sex'], valid_comparison_df['predicted_sex'], labels=labels)\n",
    "        cm_df = pd.DataFrame(cm, index=[f'Actual: {l}' for l in labels], columns=[f'Predicted: {l}' for l in labels])\n",
    "        print(cm_df)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nCould not perform validation. No valid known and predicted sexes to compare.\")"
   ],
   "id": "a4a3b676e8bb6857",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Display Key Chromosomal Statistics for All Cases (with Z-Scores) ###\n",
    "\n",
    "# This cell calculates essential statistics for each sample, including the z-scores\n",
    "# for the X and Y chromosome medians relative to the autosomal baseline.\n",
    "# This provides a clear table for debugging and analyzing model inputs.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the required data is available from previous cells\n",
    "if 'ngs_raw_df' not in locals() or 'cases_df' not in locals() or ngs_raw_df.empty or cases_df.empty:\n",
    "    print(\"Error: 'ngs_raw_df' or 'cases_df' is not loaded. Please run the data loading cells first.\", file=sys.stderr)\n",
    "else:\n",
    "    # --- Calculate Statistics for Each Case ---\n",
    "    print(\"--- Calculating Chromosomal Statistics and Z-Scores for Each Case ---\")\n",
    "\n",
    "    case_stats = []\n",
    "    for case_id, group in ngs_raw_df.groupby('case_n_number'):\n",
    "        # Isolate data for each chromosome type\n",
    "        autosomal_bins = group[(group['chromosome'] >= 1) & (group['chromosome'] <= 22)]\n",
    "        x_bins = group[group['chromosome'] == 23]\n",
    "        y_bins = group[group['chromosome'] == 24]\n",
    "\n",
    "        # Calculate base stats, handling cases where a chromosome might be missing data\n",
    "        median_auto = autosomal_bins['log2'].median() if not autosomal_bins.empty else np.nan\n",
    "        std_auto = autosomal_bins['log2'].std() if not autosomal_bins.empty else np.nan\n",
    "        median_x = x_bins['log2'].median() if not x_bins.empty else np.nan\n",
    "        median_y = y_bins['log2'].median() if not y_bins.empty else np.nan\n",
    "\n",
    "        # Calculate z-scores, handling potential division by zero\n",
    "        if pd.notna(std_auto) and std_auto > 1e-9:\n",
    "            z_score_x = (median_x - median_auto) / std_auto\n",
    "            z_score_y = (median_y - median_auto) / std_auto\n",
    "        else:\n",
    "            z_score_x, z_score_y = np.nan, np.nan\n",
    "\n",
    "        # Store all results\n",
    "        case_stats.append({\n",
    "            'case_n_number': case_id,\n",
    "            'autosomal_median': median_auto,\n",
    "            'autosomal_std': std_auto,\n",
    "            'x_median': median_x,\n",
    "            'y_median': median_y,\n",
    "            'z_score_x': z_score_x,\n",
    "            'z_score_y': z_score_y\n",
    "        })\n",
    "\n",
    "    # Convert the list of results into a DataFrame\n",
    "    stats_df = pd.DataFrame(case_stats)\n",
    "\n",
    "    # Merge with cases_df to add the 'sex' column\n",
    "    summary_df = pd.merge(cases_df[['case_n_number', 'sex']], stats_df, on='case_n_number')\n",
    "\n",
    "    # Reorder columns for maximum clarity\n",
    "    summary_df = summary_df[[\n",
    "        'case_n_number',\n",
    "        'sex',\n",
    "        'autosomal_median',\n",
    "        'autosomal_std',\n",
    "        'x_median',\n",
    "        'z_score_x',\n",
    "        'y_median',\n",
    "        'z_score_y'\n",
    "    ]]\n",
    "\n",
    "    # Set display options for better readability\n",
    "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "    print(\"\\nSummary statistics table created:\")\n",
    "\n",
    "    # Display the final table\n",
    "    display(summary_df)\n",
    "\n",
    "    # Optional: Reset float format if you don't want it for subsequent cells\n",
    "    # pd.reset_option('display.float_format')"
   ],
   "id": "e2999390ad97a0fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Simulation to Optimize Autosomal Z-Score Thresholds\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure the required data is available from previous cells\n",
    "if 'ngs_raw_df' not in locals() or 'cases_df' not in locals() or ngs_raw_df.empty or cases_df.empty:\n",
    "    print(\"Error: 'ngs_raw_df' or 'cases_df' is not loaded. Please run data loading cells first.\", file=sys.stderr)\n",
    "else:\n",
    "    # --- Pre-calculation Step (for speed) ---\n",
    "    print(\"Pre-calculating Z-scores for all samples...\")\n",
    "    z_scores = {}\n",
    "    for case_id, group in ngs_raw_df.groupby('case_n_number'):\n",
    "        y_chrom_bins = group[group['chromosome'] == 24]\n",
    "        autosomal_bins = group[(group['chromosome'] >= 1) & (group['chromosome'] <= 22)]\n",
    "        if not y_chrom_bins.empty and not autosomal_bins.empty:\n",
    "            autosomal_std = autosomal_bins['log2'].std()\n",
    "            if autosomal_std > 1e-6:\n",
    "                autosomal_mean = autosomal_bins['log2'].mean()\n",
    "                y_median = y_chrom_bins['log2'].median()\n",
    "                z_scores[case_id] = (y_median - autosomal_mean) / autosomal_std\n",
    "\n",
    "    # Convert to a DataFrame for easier processing\n",
    "    z_scores_df = pd.Series(z_scores, name='z_score').to_frame().reset_index()\n",
    "    z_scores_df = z_scores_df.rename(columns={'index': 'case_n_number'})\n",
    "    # Merge with true sex labels\n",
    "    z_scores_df = z_scores_df.merge(cases_df[['case_n_number', 'sex']], on='case_n_number')\n",
    "    print(f\"Calculated Z-scores for {len(z_scores_df)} samples.\")\n",
    "\n",
    "    # --- Helper function for the simulation ---\n",
    "    def _calculate_metrics_zscore(df, female_z_thresh, male_z_thresh):\n",
    "        y_true, y_pred, confidences = [], [], []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            z = row['z_score']\n",
    "            true_sex = row['sex']\n",
    "\n",
    "            # --- Prediction and Confidence (mirrors main function) ---\n",
    "            if z < female_z_thresh:\n",
    "                prediction = \"female\"\n",
    "                confidence = min(1.0, (female_z_thresh - z) / abs(female_z_thresh))\n",
    "            elif z > male_z_thresh:\n",
    "                prediction = \"male\"\n",
    "                confidence = min(1.0, (z - male_z_thresh) / abs(male_z_thresh))\n",
    "            else:\n",
    "                prediction = \"unknown\"\n",
    "                mid_point = (female_z_thresh + male_z_thresh) / 2\n",
    "                confidence = 1.0 - (abs(z - mid_point) / abs(mid_point - female_z_thresh))\n",
    "\n",
    "            confidences.append(np.clip(confidence, 0.0, 1.0))\n",
    "\n",
    "            if true_sex in ['male', 'female'] and prediction != 'unknown':\n",
    "                y_true.append(true_sex)\n",
    "                y_pred.append(prediction)\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy_score(y_true, y_pred) if y_true else 0.0,\n",
    "            'confidence': np.mean(confidences) if confidences else 0.0\n",
    "        }\n",
    "\n",
    "    # --- Simulation Setup ---\n",
    "    print(\"\\n--- Starting Parameter Optimization for Z-Score Model ---\")\n",
    "\n",
    "    ACCURACY_WEIGHT = 0.7\n",
    "    CONFIDENCE_WEIGHT = 0.3\n",
    "\n",
    "    # Define search space for z-score thresholds\n",
    "    female_thresholds = np.arange(-5.0, -1.0, 0.1)\n",
    "    male_thresholds = np.arange(-3.0, 1.0, 0.1)\n",
    "\n",
    "    total_iterations = len(female_thresholds) * len(male_thresholds)\n",
    "    print(f\"Search space: {len(female_thresholds)} (female) x {len(male_thresholds)} (male) = {total_iterations} total combinations.\")\n",
    "\n",
    "    # --- Grid Search Execution ---\n",
    "    best_combined_score = -1.0\n",
    "    best_params = {}\n",
    "    best_metrics = {}\n",
    "    iteration_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for f_thresh in female_thresholds:\n",
    "        for m_thresh in male_thresholds:\n",
    "            iteration_count += 1\n",
    "            if not f_thresh < m_thresh: continue # Ensure female threshold is lower than male\n",
    "\n",
    "            metrics = _calculate_metrics_zscore(z_scores_df, f_thresh, m_thresh)\n",
    "            combined_score = (ACCURACY_WEIGHT * metrics['accuracy']) + (CONFIDENCE_WEIGHT * metrics['confidence'])\n",
    "\n",
    "            if combined_score > best_combined_score:\n",
    "                best_combined_score = combined_score\n",
    "                best_params = {\n",
    "                    'female_z_thresh': round(f_thresh, 2),\n",
    "                    'male_z_thresh': round(m_thresh, 2)\n",
    "                }\n",
    "                best_metrics = metrics\n",
    "                print(f\"*** New best! Score: {best_combined_score:.4f} \"\n",
    "                      f\"(Acc: {best_metrics['accuracy']:.2%}, Conf: {best_metrics['confidence']:.2%}) | \"\n",
    "                      f\"Params: F_z={best_params['female_z_thresh']}, M_z={best_params['male_z_thresh']} ***\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"\\n--- Optimization Complete ---\")\n",
    "    print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    if not best_params:\n",
    "        print(\"\\nCould not find any valid parameter combinations.\")\n",
    "    else:\n",
    "        print(\"\\n Best Z-Score Thresholds Found:\")\n",
    "        print(f\"  - female_z_thresh = {best_params['female_z_thresh']}\")\n",
    "        print(f\"  - male_z_thresh   = {best_params['male_z_thresh']}\")\n",
    "        print(f\"\\n Resulting Metrics with these parameters:\")\n",
    "        print(f\"  - Combined Score: {best_combined_score:.4f}\")\n",
    "        print(f\"  - Accuracy:       {best_metrics['accuracy']:.3%}\")\n",
    "        print(f\"  - Avg Confidence: {best_metrics['confidence']:.3%}\")\n",
    "        print(\"\\nSuggestion: Update the default parameters in the 'predict_sex_autosomal_zscore' function with these values.\")"
   ],
   "id": "80da1b00cf5e99cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
